{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Opciones_Barrera.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S3lkZbim1ao"
      },
      "source": [
        "#Opciones Barrera.\r\n",
        "\r\n",
        "Una opción financiera es derivado financiero que supone un contrato de compra o venta de un activo subyacente, el cual otorga el derecho al comprador de la opción de comprar o vender el activo subyacente acordado en un futuro acordado previamente, según sea opción de compra u opción de venta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVfjXJdkBmVt"
      },
      "source": [
        "##Opciones exóticas.\r\n",
        "\r\n",
        "Exóticas son las opciones cuyas características difieren de las llamadas “estándar”. Las opciones exóticas son productos algo más sofisticados que las opciones estándar y tratan de adaptar el mundo de las opciones a las necesidades de los usuarios, gestionando de forma más flexible sus riesgos o minimizando los costes de las opciones estándar.\r\n",
        "\r\n",
        "Las  opciones  tipo  barrera  son  una  variación de  Opción  Exótica,  que  se  cancelan  o  se activan dependiendo de si el precio del activo subyacente  alcanza  cierto  valor  durante  un periodo   determinado,   independientemente de su valor al momento del vencimiento de la opción. Estas opciones tienen la característica de ser “más baratas”$^{1}$ que  las  opciones plain vanilla$^{2}$,  razón  por  la  cual  pueden  llegar  a  ser muy atractivas.\r\n",
        "\r\n",
        "Las  opciones  tipo  barrera  se  clasifican  en Opciones con Barrera de Entrada knock-in y con Barrera de Salida knock-out.  En  las primeras,  si  durante  el  periodo  pactado,  el subyacente   alcanza   el   nivel   determinado previamente o la barrera, la opción pasa de ser una condicional a ser una opción de compra o  de  venta plain  vanilla.  Por  el  contrario,  en las opciones con barrera de salida knock-out,cuando  se  alcanza  la  barrera,  la  opción  deja de  existir  o  expira  sin  ningún  valor  en  el momento de la activación. Las opciones tipo barrera  pueden  ser  Europeas  o  Americanas y  clasificarse  en:  opciones  abajo  y  de  salida down-out,  o  abajo  y  de  entrada down-in,  en las cuales la barrera se encuentra por debajo del nivel inicial del activo; o arriba y de salida up-out  o  arriba  y  de  entrada up-in,  en  las cuales la barrera se encuentra por encima del nivel  inicial  del  activo,  lo  que  implica  ocho diferentes  tipos  de  opciones  considerando que cada uno de ellos puede ser Call o Put.\r\n",
        "\r\n",
        "1. El valor total de una opción corresponde a la suma del valor intrínseco  y  el  valor  tiempo  de  la  misma.  Es  precisamente la existencia de estos valores, lo que explica el menor precio de las opciones tipo barrera, comparadas con las Opciones Plain  Vanilla,  ya  que  la  existencia  de  la  barrera  crea  un límite  al  valor  intrínseco  y  al  valor  tiempo  de  la  opción, disminuyendo así su valor total.\r\n",
        "\r\n",
        "2. Se conoce como producto “plain vanilla” al producto básico, es decir, el más estándar de los productos financieros. En divisas, entre los productos “plain vanilla” se incluyen los productos de cobertura del riesgo, tales como los seguros de cambio de divisas y las opciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKgLuw7F7gZS"
      },
      "source": [
        "<center>\r\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Figuras/1.png?raw=1\" width=\"600\"> \r\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qKyi6Kl7lsk"
      },
      "source": [
        "<center>\r\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Figuras/2.jpg?raw=1\" width=\"600\"> \r\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFvSKAPB015z"
      },
      "source": [
        "Este método supone que el proceso seguido por el precio del activo subyacente es de la siguiente forma\r\n",
        "$$ dS= \\bar{\\mu} Sdt + \\sigma Sdz$$\r\n",
        "\r\n",
        "donde \r\n",
        "\r\n",
        "*   dz: es un proceso de Winner con dz=dz y $z= \\epsilon \\sqrt{t}$ y $\\epsilon \\backsim$ N(0,1).\r\n",
        "*   $\\bar{\\mu}$ : es el valor esperado de los retornos del activo en  un  mundo  de  riesgo  neutral.\r\n",
        "*   $\\sigma$: es la volatilidad del activo.\r\n",
        "*   S: precio del activo subyacente.\r\n",
        "\r\n",
        "Para simular la ruta seguida por S, se utiliza la siguiente ecuación: \r\n",
        "\r\n",
        "$$ S(t +\\Delta t)= S(t) exp \\Big\\{ (r_{d}-r_{j} -\\frac{\\sigma^{2}}{2})\\Delta t +\\sigma \\epsilon \\sqrt{\\Delta t}\\Big\\} \\tag{2} $$\r\n",
        "\r\n",
        "\r\n",
        "Con la ecuación (2) se generan las diferentes trayectorias que puede tomar el precio del activo subyacente durante la vida de la opción. Una vez se genera la ruta, se determina el valor máximo o  mínimo  que  ha  tomado  el  activo  durante la  vida  de  la  opción  para  evaluarlo  contra  la barrera.  Finalmente  se  calcula  el payoff  de  la opción  como  el $Max(St-K,0)$  para  las  opciones Call, o $Max(K-St,0)$ para las opciones Put.\r\n",
        "\r\n",
        "La  exactitud  que  puede  proporcionar  este método   numérico   está   relacionada   con el  número  de  corridas  que  se  ejecuten  en una   simulación.   Además   del   cálculo   del promedio  de  los  pagos  descontados  que  se generan  en  las  corridas,  es  decir,  el  precio alcanzado para la opción, se debe obtener el error  de  la  estimación.  Este  no  es  otra  cosa que  la  desviación  estándar  generada  en  la simulación,  divida  por  la  raíz  cuadrada  del número  de  corridas  utilizadas.  Esta  medida permite  construir  intervalos  de  confianza que  muestran  que  la  incertidumbre  acerca del   valor   de   la   opción   es   inversamente proporcional  a  la  raíz  cuadrada  del  número de corridas. En otras palabras, para alcanzar el  doble  de  exactitud  en  una  estimación,  se deberá cuadruplicar el número de corridas\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRsMB90cBmgU"
      },
      "source": [
        "El modelo Black-Scholes se puede utilizar de manera eficiente para fijar el precio de las opciones “simples” con la regla de ejercicio europea. Las opciones como la opción Barrera y la opción Basket tienen una estructura complicada sin una solución analítica simple. La simulación de Monte Carlo es una forma eficaz de ponerles precio. Para obtener un precio exacto con una pequeña variación, necesita muchas rutas de simulación, lo cual es computacionalmente intensivo.\r\n",
        "\r\n",
        "Afortunadamente, cada una de las rutas de simulación es independiente y puede aprovechar la GPU NVIDIA de múltiples núcleos para acelerar el cálculo dentro de un nodo o incluso expandirlo a múltiples servidores, si es necesario. El uso de GPU puede acelerar el cálculo en órdenes de magnitud debido a la paralelización de las rutas independientes.\r\n",
        "\r\n",
        "Tradicionalmente, la simulación Monte Carlo en GPU se implementa en código CUDA C / C ++. Los científicos de datos deben administrar la memoria explícitamente y escribir mucho código repetitivo, lo que plantea desafíos para el mantenimiento del código y la eficiencia de producción."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEDRalIeJ2H4",
        "outputId": "9586db1b-76c9-4f92-fcf0-123eb291ea47"
      },
      "source": [
        "!pip install cupy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cupy\n",
            "  Using cached https://files.pythonhosted.org/packages/87/cb/868f183aa58c65a761a4d4b14b870dd98d5bda4c1524c399a11a0adebed9/cupy-8.3.0.tar.gz\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYkOkHlRBx3d",
        "outputId": "d5b34d28-3aed-4a0d-a6db-effca4dab9a8"
      },
      "source": [
        "!apt-get install cudf"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package cudf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JnaTcu2JMKI",
        "outputId": "cc8af32d-c985-4ff9-812a-dea4e8674b4c"
      },
      "source": [
        "!git clone https://github.com/rapidsai/gQuant/tree/develop/notebooks/asian_barrier_option"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cuda_pricing.cu'...\n",
            "fatal: repository 'https://github.com/rapidsai/gQuant/blob/develop/notebooks/asian_barrier_option/cuda_pricing.cu/' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "6bs_WI29jdww",
        "outputId": "762629dc-9704-4af5-bc2a-85e94f7467e5"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-76f8b192-7120-4aad-b679-1e3ff192a453\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-76f8b192-7120-4aad-b679-1e3ff192a453\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cuda_pricing.cu to cuda_pricing.cu\n",
            "Saving helper_cuda.h to helper_cuda.h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuda_pricing.cu': b'#include <vector>\\r\\n#include <stdio.h>\\r\\n#include <iostream>\\r\\n#include <chrono>\\r\\n#include <cuda_runtime.h>\\r\\n#include <helper_cuda.h>\\r\\n#include <curand.h>\\r\\n \\r\\n#define CHECKCURAND(expression)                         \\\\\\r\\n  {                                                     \\\\\\r\\n    curandStatus_t status = (expression);                         \\\\\\r\\n    if (status != CURAND_STATUS_SUCCESS) {                        \\\\\\r\\n      std::cerr << \"Curand Error on line \" << __LINE__<< std::endl;     \\\\\\r\\n      std::exit(EXIT_FAILURE);                                          \\\\\\r\\n    }                                                                   \\\\\\r\\n  }\\r\\n\\r\\n// atomicAdd is introduced for compute capability >=6.0\\r\\n#if !defined(__CUDA_ARCH__) || __CUDA_ARCH__ >= 600\\r\\n#else\\r\\n__device__ double atomicAdd(double* address, double val)\\r\\n{\\r\\n      printf(\"device arch <=600\\\\n\");\\r\\n        unsigned long long int* address_as_ull = (unsigned long long int*)address;\\r\\n          unsigned long long int old = *address_as_ull, assumed;\\r\\n            do {\\r\\n                    assumed = old;\\r\\n                        old = atomicCAS(address_as_ull, assumed,\\r\\n                                                    __double_as_longlong(val + __longlong_as_double(assumed)));\\r\\n                          } while (assumed != old);\\r\\n              return __longlong_as_double(old);\\r\\n}\\r\\n#endif\\r\\n\\r\\n__global__ void sumPayoffKernel(float *d_s, const unsigned N_PATHS, double *mysum)\\r\\n{\\r\\n  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\\r\\n  unsigned stride = blockDim.x * gridDim.x;\\r\\n  unsigned tid = threadIdx.x;\\r\\n\\r\\n  extern __shared__ double smdata[];\\r\\n  smdata[tid] = 0.0;\\r\\n\\r\\n  for (unsigned i = idx; i<N_PATHS; i+=stride)\\r\\n  {\\r\\n    smdata[tid] += (double) d_s[i];\\r\\n  }\\r\\n\\r\\n  for (unsigned s=blockDim.x/2; s>0; s>>=1)\\r\\n  {\\r\\n    __syncthreads();\\r\\n    if (tid < s) smdata[tid] += smdata[tid + s];\\r\\n  }\\r\\n\\r\\n  if (tid == 0)\\r\\n  {\\r\\n    atomicAdd(mysum, smdata[0]);\\r\\n  }\\r\\n}\\r\\n\\r\\n__global__ void barrier_option(\\r\\n    float *d_s,\\r\\n    const float T,\\r\\n    const float K,\\r\\n    const float B,\\r\\n    const float S0,\\r\\n    const float sigma,\\r\\n    const float mu,\\r\\n    const float r,\\r\\n    const float * d_normals,\\r\\n    const long N_STEPS,\\r\\n    const long N_PATHS)\\r\\n{\\r\\n  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\\r\\n  unsigned stride = blockDim.x * gridDim.x;\\r\\n  const float tmp1 = mu*T/N_STEPS;\\r\\n  const float tmp2 = exp(-r*T);\\r\\n  const float tmp3 = sqrt(T/N_STEPS);\\r\\n  double running_average = 0.0;\\r\\n\\r\\n  for (unsigned i = idx; i<N_PATHS; i+=stride)\\r\\n  {\\r\\n    float s_curr = S0;\\r\\n    for(unsigned n = 0; n < N_STEPS; n++){\\r\\n       s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS];\\r\\n       running_average += (s_curr - running_average) / (n + 1.0) ;\\r\\n       if (running_average <= B){\\r\\n           break;\\r\\n       }\\r\\n    }\\r\\n\\r\\n    float payoff = (running_average>K ? running_average-K : 0.f);\\r\\n    d_s[i] = tmp2 * payoff;\\r\\n  }\\r\\n}\\r\\n\\r\\nint main(int argc, char *argv[]) {\\r\\n  try {\\r\\n    // declare variables and constants\\r\\n    size_t N_PATHS = 8192000;\\r\\n    size_t N_STEPS = 365;\\r\\n    if (argc >= 2)  N_PATHS = atoi(argv[1]);\\r\\n\\r\\n    if (argc >= 3)  N_STEPS = atoi(argv[2]);\\r\\n\\r\\n    const float T = 1.0f;\\r\\n    const float K = 110.0f;\\r\\n    const float B = 100.0f;\\r\\n    const float S0 = 120.0f;\\r\\n    const float sigma = 0.35f;\\r\\n    const float mu = 0.1f;\\r\\n    const float r = 0.05f;\\r\\n\\r\\n\\r\\n    double gpu_sum{0.0};\\r\\n\\r\\n    int devID{0};\\r\\n    cudaDeviceProp deviceProps;\\r\\n\\r\\n    checkCudaErrors(cudaGetDeviceProperties(&deviceProps, devID));\\r\\n    printf(\"CUDA device [%s]\\\\n\", deviceProps.name);\\r\\n    printf(\"GPU Device %d: \\\\\"%s\\\\\" with compute capability %d.%d\\\\n\\\\n\", devID, deviceProps.name, deviceProps.major, deviceProps.minor);\\r\\n    // Generate random numbers on the device\\r\\n    curandGenerator_t curandGenerator;\\r\\n    CHECKCURAND(curandCreateGenerator(&curandGenerator, CURAND_RNG_PSEUDO_MTGP32));\\r\\n    CHECKCURAND(curandSetPseudoRandomGeneratorSeed(curandGenerator, 1234ULL)) ;\\r\\n\\r\\n    const size_t N_NORMALS = (size_t)N_STEPS * N_PATHS;\\r\\n    float *d_normals;\\r\\n    checkCudaErrors(cudaMalloc(&d_normals, N_NORMALS * sizeof(float)));\\r\\n    CHECKCURAND(curandGenerateNormal(curandGenerator, d_normals, N_NORMALS, 0.0f, 1.0f));\\r\\n    cudaDeviceSynchronize();\\r\\n\\r\\n  \\t// before kernel launch, check the max potential blockSize\\r\\n  \\tint BLOCK_SIZE, GRID_SIZE;\\r\\n  \\tcheckCudaErrors(cudaOccupancyMaxPotentialBlockSize(&GRID_SIZE,\\r\\n  \\t                                                   &BLOCK_SIZE,\\r\\n  \\t                                                   barrier_option,\\r\\n  \\t                                                   0, N_PATHS));\\r\\n\\r\\n  \\tstd::cout << \"suggested block size \" << BLOCK_SIZE\\r\\n  \\t          << \" \\\\nsuggested grid size \" << GRID_SIZE\\r\\n  \\t          << std::endl;\\r\\n\\r\\n  \\tstd::cout << \"Used grid size \" << GRID_SIZE << std::endl;\\r\\n\\r\\n  \\t// Kernel launch\\r\\n  \\tauto t1=std::chrono::high_resolution_clock::now();\\r\\n\\r\\n  \\tfloat *d_s;\\r\\n  \\tcheckCudaErrors(cudaMalloc(&d_s, N_PATHS*sizeof(float)));\\r\\n\\r\\n  \\tauto t3=std::chrono::high_resolution_clock::now();\\r\\n  \\tbarrier_option<<<GRID_SIZE, BLOCK_SIZE>>>(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS);\\r\\n  \\tcudaDeviceSynchronize();\\r\\n  \\tauto t4=std::chrono::high_resolution_clock::now();\\r\\n\\r\\n  \\tdouble* mySum;\\r\\n  \\tcheckCudaErrors(cudaMallocManaged(&mySum, sizeof(double)));\\r\\n  \\tsumPayoffKernel<<<GRID_SIZE, BLOCK_SIZE, BLOCK_SIZE*sizeof(double)>>>(d_s, N_PATHS, mySum);\\r\\n  \\tcudaDeviceSynchronize();\\r\\n  \\tauto t5=std::chrono::high_resolution_clock::now();\\r\\n\\r\\n  \\tstd::cout << \"sumPayoffKernel takes \"\\r\\n  \\t          << std::chrono::duration_cast<std::chrono::microseconds>(t5-t4).count() / 1000.f\\r\\n  \\t          << \" ms\\\\n\";\\r\\n\\r\\n  \\tgpu_sum = mySum[0] / N_PATHS;\\r\\n\\r\\n  \\tauto t2=std::chrono::high_resolution_clock::now();\\r\\n\\r\\n  \\t// clean up\\r\\n  \\tCHECKCURAND(curandDestroyGenerator( curandGenerator )) ;\\r\\n  \\tcheckCudaErrors(cudaFree(d_s));\\r\\n  \\tcheckCudaErrors(cudaFree(d_normals));\\r\\n  \\tcheckCudaErrors(cudaFree(mySum));\\r\\n\\r\\n  \\tstd::cout << \"price \"\\r\\n              << gpu_sum\\r\\n              << \" time \"\\r\\n  \\t          << std::chrono::duration_cast<std::chrono::microseconds>(t5-t1).count() / 1000.f\\r\\n  \\t          << \" ms\\\\n\";\\r\\n  }\\r\\n\\r\\n  catch(std::\\r\\n        exception& e)\\r\\n  {\\r\\n    std::cout<< \"exception: \" << e.what() << \"\\\\n\";\\r\\n  }\\r\\n}',\n",
              " 'helper_cuda.h': b'/**\\r\\n * Copyright 1993-2017 NVIDIA Corporation.  All rights reserved.\\r\\n *\\r\\n * Please refer to the NVIDIA end user license agreement (EULA) associated\\r\\n * with this source code for terms and conditions that govern your use of\\r\\n * this software. Any use, reproduction, disclosure, or distribution of\\r\\n * this software and related documentation outside the terms of the EULA\\r\\n * is strictly prohibited.\\r\\n *\\r\\n */\\r\\n\\r\\n////////////////////////////////////////////////////////////////////////////////\\r\\n// These are CUDA Helper functions for initialization and error checking\\r\\n\\r\\n#ifndef COMMON_HELPER_CUDA_H_\\r\\n#define COMMON_HELPER_CUDA_H_\\r\\n\\r\\n#pragma once\\r\\n\\r\\n#include <stdint.h>\\r\\n#include <stdio.h>\\r\\n#include <stdlib.h>\\r\\n#include <string.h>\\r\\n\\r\\n#include <helper_string.h>\\r\\n\\r\\n#ifndef EXIT_WAIVED\\r\\n#define EXIT_WAIVED 2\\r\\n#endif\\r\\n\\r\\n// Note, it is required that your SDK sample to include the proper header\\r\\n// files, please refer the CUDA examples for examples of the needed CUDA\\r\\n// headers, which may change depending on which CUDA functions are used.\\r\\n\\r\\n// CUDA Runtime error messages\\r\\n#ifdef __DRIVER_TYPES_H__\\r\\nstatic const char *_cudaGetErrorEnum(cudaError_t error) {\\r\\n  return cudaGetErrorName(error);\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef CUDA_DRIVER_API\\r\\n// CUDA Driver API errors\\r\\nstatic const char *_cudaGetErrorEnum(CUresult error) {\\r\\n  static char unknown[] = \"<unknown>\";\\r\\n  const char *ret = NULL;\\r\\n  cuGetErrorName(error, &ret);\\r\\n  return ret ? ret : unknown;\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef CUBLAS_API_H_\\r\\n// cuBLAS API errors\\r\\nstatic const char *_cudaGetErrorEnum(cublasStatus_t error) {\\r\\n  switch (error) {\\r\\n    case CUBLAS_STATUS_SUCCESS:\\r\\n      return \"CUBLAS_STATUS_SUCCESS\";\\r\\n\\r\\n    case CUBLAS_STATUS_NOT_INITIALIZED:\\r\\n      return \"CUBLAS_STATUS_NOT_INITIALIZED\";\\r\\n\\r\\n    case CUBLAS_STATUS_ALLOC_FAILED:\\r\\n      return \"CUBLAS_STATUS_ALLOC_FAILED\";\\r\\n\\r\\n    case CUBLAS_STATUS_INVALID_VALUE:\\r\\n      return \"CUBLAS_STATUS_INVALID_VALUE\";\\r\\n\\r\\n    case CUBLAS_STATUS_ARCH_MISMATCH:\\r\\n      return \"CUBLAS_STATUS_ARCH_MISMATCH\";\\r\\n\\r\\n    case CUBLAS_STATUS_MAPPING_ERROR:\\r\\n      return \"CUBLAS_STATUS_MAPPING_ERROR\";\\r\\n\\r\\n    case CUBLAS_STATUS_EXECUTION_FAILED:\\r\\n      return \"CUBLAS_STATUS_EXECUTION_FAILED\";\\r\\n\\r\\n    case CUBLAS_STATUS_INTERNAL_ERROR:\\r\\n      return \"CUBLAS_STATUS_INTERNAL_ERROR\";\\r\\n\\r\\n    case CUBLAS_STATUS_NOT_SUPPORTED:\\r\\n      return \"CUBLAS_STATUS_NOT_SUPPORTED\";\\r\\n\\r\\n    case CUBLAS_STATUS_LICENSE_ERROR:\\r\\n      return \"CUBLAS_STATUS_LICENSE_ERROR\";\\r\\n  }\\r\\n\\r\\n  return \"<unknown>\";\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef _CUFFT_H_\\r\\n// cuFFT API errors\\r\\nstatic const char *_cudaGetErrorEnum(cufftResult error) {\\r\\n  switch (error) {\\r\\n    case CUFFT_SUCCESS:\\r\\n      return \"CUFFT_SUCCESS\";\\r\\n\\r\\n    case CUFFT_INVALID_PLAN:\\r\\n      return \"CUFFT_INVALID_PLAN\";\\r\\n\\r\\n    case CUFFT_ALLOC_FAILED:\\r\\n      return \"CUFFT_ALLOC_FAILED\";\\r\\n\\r\\n    case CUFFT_INVALID_TYPE:\\r\\n      return \"CUFFT_INVALID_TYPE\";\\r\\n\\r\\n    case CUFFT_INVALID_VALUE:\\r\\n      return \"CUFFT_INVALID_VALUE\";\\r\\n\\r\\n    case CUFFT_INTERNAL_ERROR:\\r\\n      return \"CUFFT_INTERNAL_ERROR\";\\r\\n\\r\\n    case CUFFT_EXEC_FAILED:\\r\\n      return \"CUFFT_EXEC_FAILED\";\\r\\n\\r\\n    case CUFFT_SETUP_FAILED:\\r\\n      return \"CUFFT_SETUP_FAILED\";\\r\\n\\r\\n    case CUFFT_INVALID_SIZE:\\r\\n      return \"CUFFT_INVALID_SIZE\";\\r\\n\\r\\n    case CUFFT_UNALIGNED_DATA:\\r\\n      return \"CUFFT_UNALIGNED_DATA\";\\r\\n\\r\\n    case CUFFT_INCOMPLETE_PARAMETER_LIST:\\r\\n      return \"CUFFT_INCOMPLETE_PARAMETER_LIST\";\\r\\n\\r\\n    case CUFFT_INVALID_DEVICE:\\r\\n      return \"CUFFT_INVALID_DEVICE\";\\r\\n\\r\\n    case CUFFT_PARSE_ERROR:\\r\\n      return \"CUFFT_PARSE_ERROR\";\\r\\n\\r\\n    case CUFFT_NO_WORKSPACE:\\r\\n      return \"CUFFT_NO_WORKSPACE\";\\r\\n\\r\\n    case CUFFT_NOT_IMPLEMENTED:\\r\\n      return \"CUFFT_NOT_IMPLEMENTED\";\\r\\n\\r\\n    case CUFFT_LICENSE_ERROR:\\r\\n      return \"CUFFT_LICENSE_ERROR\";\\r\\n\\r\\n    case CUFFT_NOT_SUPPORTED:\\r\\n      return \"CUFFT_NOT_SUPPORTED\";\\r\\n  }\\r\\n\\r\\n  return \"<unknown>\";\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef CUSPARSEAPI\\r\\n// cuSPARSE API errors\\r\\nstatic const char *_cudaGetErrorEnum(cusparseStatus_t error) {\\r\\n  switch (error) {\\r\\n    case CUSPARSE_STATUS_SUCCESS:\\r\\n      return \"CUSPARSE_STATUS_SUCCESS\";\\r\\n\\r\\n    case CUSPARSE_STATUS_NOT_INITIALIZED:\\r\\n      return \"CUSPARSE_STATUS_NOT_INITIALIZED\";\\r\\n\\r\\n    case CUSPARSE_STATUS_ALLOC_FAILED:\\r\\n      return \"CUSPARSE_STATUS_ALLOC_FAILED\";\\r\\n\\r\\n    case CUSPARSE_STATUS_INVALID_VALUE:\\r\\n      return \"CUSPARSE_STATUS_INVALID_VALUE\";\\r\\n\\r\\n    case CUSPARSE_STATUS_ARCH_MISMATCH:\\r\\n      return \"CUSPARSE_STATUS_ARCH_MISMATCH\";\\r\\n\\r\\n    case CUSPARSE_STATUS_MAPPING_ERROR:\\r\\n      return \"CUSPARSE_STATUS_MAPPING_ERROR\";\\r\\n\\r\\n    case CUSPARSE_STATUS_EXECUTION_FAILED:\\r\\n      return \"CUSPARSE_STATUS_EXECUTION_FAILED\";\\r\\n\\r\\n    case CUSPARSE_STATUS_INTERNAL_ERROR:\\r\\n      return \"CUSPARSE_STATUS_INTERNAL_ERROR\";\\r\\n\\r\\n    case CUSPARSE_STATUS_MATRIX_TYPE_NOT_SUPPORTED:\\r\\n      return \"CUSPARSE_STATUS_MATRIX_TYPE_NOT_SUPPORTED\";\\r\\n  }\\r\\n\\r\\n  return \"<unknown>\";\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef CUSOLVER_COMMON_H_\\r\\n// cuSOLVER API errors\\r\\nstatic const char *_cudaGetErrorEnum(cusolverStatus_t error) {\\r\\n  switch (error) {\\r\\n    case CUSOLVER_STATUS_SUCCESS:\\r\\n      return \"CUSOLVER_STATUS_SUCCESS\";\\r\\n    case CUSOLVER_STATUS_NOT_INITIALIZED:\\r\\n      return \"CUSOLVER_STATUS_NOT_INITIALIZED\";\\r\\n    case CUSOLVER_STATUS_ALLOC_FAILED:\\r\\n      return \"CUSOLVER_STATUS_ALLOC_FAILED\";\\r\\n    case CUSOLVER_STATUS_INVALID_VALUE:\\r\\n      return \"CUSOLVER_STATUS_INVALID_VALUE\";\\r\\n    case CUSOLVER_STATUS_ARCH_MISMATCH:\\r\\n      return \"CUSOLVER_STATUS_ARCH_MISMATCH\";\\r\\n    case CUSOLVER_STATUS_MAPPING_ERROR:\\r\\n      return \"CUSOLVER_STATUS_MAPPING_ERROR\";\\r\\n    case CUSOLVER_STATUS_EXECUTION_FAILED:\\r\\n      return \"CUSOLVER_STATUS_EXECUTION_FAILED\";\\r\\n    case CUSOLVER_STATUS_INTERNAL_ERROR:\\r\\n      return \"CUSOLVER_STATUS_INTERNAL_ERROR\";\\r\\n    case CUSOLVER_STATUS_MATRIX_TYPE_NOT_SUPPORTED:\\r\\n      return \"CUSOLVER_STATUS_MATRIX_TYPE_NOT_SUPPORTED\";\\r\\n    case CUSOLVER_STATUS_NOT_SUPPORTED:\\r\\n      return \"CUSOLVER_STATUS_NOT_SUPPORTED \";\\r\\n    case CUSOLVER_STATUS_ZERO_PIVOT:\\r\\n      return \"CUSOLVER_STATUS_ZERO_PIVOT\";\\r\\n    case CUSOLVER_STATUS_INVALID_LICENSE:\\r\\n      return \"CUSOLVER_STATUS_INVALID_LICENSE\";\\r\\n  }\\r\\n\\r\\n  return \"<unknown>\";\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef CURAND_H_\\r\\n// cuRAND API errors\\r\\nstatic const char *_cudaGetErrorEnum(curandStatus_t error) {\\r\\n  switch (error) {\\r\\n    case CURAND_STATUS_SUCCESS:\\r\\n      return \"CURAND_STATUS_SUCCESS\";\\r\\n\\r\\n    case CURAND_STATUS_VERSION_MISMATCH:\\r\\n      return \"CURAND_STATUS_VERSION_MISMATCH\";\\r\\n\\r\\n    case CURAND_STATUS_NOT_INITIALIZED:\\r\\n      return \"CURAND_STATUS_NOT_INITIALIZED\";\\r\\n\\r\\n    case CURAND_STATUS_ALLOCATION_FAILED:\\r\\n      return \"CURAND_STATUS_ALLOCATION_FAILED\";\\r\\n\\r\\n    case CURAND_STATUS_TYPE_ERROR:\\r\\n      return \"CURAND_STATUS_TYPE_ERROR\";\\r\\n\\r\\n    case CURAND_STATUS_OUT_OF_RANGE:\\r\\n      return \"CURAND_STATUS_OUT_OF_RANGE\";\\r\\n\\r\\n    case CURAND_STATUS_LENGTH_NOT_MULTIPLE:\\r\\n      return \"CURAND_STATUS_LENGTH_NOT_MULTIPLE\";\\r\\n\\r\\n    case CURAND_STATUS_DOUBLE_PRECISION_REQUIRED:\\r\\n      return \"CURAND_STATUS_DOUBLE_PRECISION_REQUIRED\";\\r\\n\\r\\n    case CURAND_STATUS_LAUNCH_FAILURE:\\r\\n      return \"CURAND_STATUS_LAUNCH_FAILURE\";\\r\\n\\r\\n    case CURAND_STATUS_PREEXISTING_FAILURE:\\r\\n      return \"CURAND_STATUS_PREEXISTING_FAILURE\";\\r\\n\\r\\n    case CURAND_STATUS_INITIALIZATION_FAILED:\\r\\n      return \"CURAND_STATUS_INITIALIZATION_FAILED\";\\r\\n\\r\\n    case CURAND_STATUS_ARCH_MISMATCH:\\r\\n      return \"CURAND_STATUS_ARCH_MISMATCH\";\\r\\n\\r\\n    case CURAND_STATUS_INTERNAL_ERROR:\\r\\n      return \"CURAND_STATUS_INTERNAL_ERROR\";\\r\\n  }\\r\\n\\r\\n  return \"<unknown>\";\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef NVJPEGAPI\\r\\n// nvJPEG API errors\\r\\nstatic const char *_cudaGetErrorEnum(nvjpegStatus_t error) {\\r\\n  switch (error) {\\r\\n    case NVJPEG_STATUS_SUCCESS:\\r\\n      return \"NVJPEG_STATUS_SUCCESS\";\\r\\n\\r\\n    case NVJPEG_STATUS_NOT_INITIALIZED:\\r\\n      return \"NVJPEG_STATUS_NOT_INITIALIZED\";\\r\\n\\r\\n    case NVJPEG_STATUS_INVALID_PARAMETER:\\r\\n      return \"NVJPEG_STATUS_INVALID_PARAMETER\";\\r\\n\\r\\n    case NVJPEG_STATUS_BAD_JPEG:\\r\\n      return \"NVJPEG_STATUS_BAD_JPEG\";\\r\\n\\r\\n    case NVJPEG_STATUS_JPEG_NOT_SUPPORTED:\\r\\n      return \"NVJPEG_STATUS_JPEG_NOT_SUPPORTED\";\\r\\n\\r\\n    case NVJPEG_STATUS_ALLOCATOR_FAILURE:\\r\\n      return \"NVJPEG_STATUS_ALLOCATOR_FAILURE\";\\r\\n\\r\\n    case NVJPEG_STATUS_EXECUTION_FAILED:\\r\\n      return \"NVJPEG_STATUS_EXECUTION_FAILED\";\\r\\n\\r\\n    case NVJPEG_STATUS_ARCH_MISMATCH:\\r\\n      return \"NVJPEG_STATUS_ARCH_MISMATCH\";\\r\\n\\r\\n    case NVJPEG_STATUS_INTERNAL_ERROR:\\r\\n      return \"NVJPEG_STATUS_INTERNAL_ERROR\";\\r\\n  }\\r\\n\\r\\n  return \"<unknown>\";\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef NV_NPPIDEFS_H\\r\\n// NPP API errors\\r\\nstatic const char *_cudaGetErrorEnum(NppStatus error) {\\r\\n  switch (error) {\\r\\n    case NPP_NOT_SUPPORTED_MODE_ERROR:\\r\\n      return \"NPP_NOT_SUPPORTED_MODE_ERROR\";\\r\\n\\r\\n    case NPP_ROUND_MODE_NOT_SUPPORTED_ERROR:\\r\\n      return \"NPP_ROUND_MODE_NOT_SUPPORTED_ERROR\";\\r\\n\\r\\n    case NPP_RESIZE_NO_OPERATION_ERROR:\\r\\n      return \"NPP_RESIZE_NO_OPERATION_ERROR\";\\r\\n\\r\\n    case NPP_NOT_SUFFICIENT_COMPUTE_CAPABILITY:\\r\\n      return \"NPP_NOT_SUFFICIENT_COMPUTE_CAPABILITY\";\\r\\n\\r\\n#if ((NPP_VERSION_MAJOR << 12) + (NPP_VERSION_MINOR << 4)) <= 0x5000\\r\\n\\r\\n    case NPP_BAD_ARG_ERROR:\\r\\n      return \"NPP_BAD_ARGUMENT_ERROR\";\\r\\n\\r\\n    case NPP_COEFF_ERROR:\\r\\n      return \"NPP_COEFFICIENT_ERROR\";\\r\\n\\r\\n    case NPP_RECT_ERROR:\\r\\n      return \"NPP_RECTANGLE_ERROR\";\\r\\n\\r\\n    case NPP_QUAD_ERROR:\\r\\n      return \"NPP_QUADRANGLE_ERROR\";\\r\\n\\r\\n    case NPP_MEM_ALLOC_ERR:\\r\\n      return \"NPP_MEMORY_ALLOCATION_ERROR\";\\r\\n\\r\\n    case NPP_HISTO_NUMBER_OF_LEVELS_ERROR:\\r\\n      return \"NPP_HISTOGRAM_NUMBER_OF_LEVELS_ERROR\";\\r\\n\\r\\n    case NPP_INVALID_INPUT:\\r\\n      return \"NPP_INVALID_INPUT\";\\r\\n\\r\\n    case NPP_POINTER_ERROR:\\r\\n      return \"NPP_POINTER_ERROR\";\\r\\n\\r\\n    case NPP_WARNING:\\r\\n      return \"NPP_WARNING\";\\r\\n\\r\\n    case NPP_ODD_ROI_WARNING:\\r\\n      return \"NPP_ODD_ROI_WARNING\";\\r\\n#else\\r\\n\\r\\n    // These are for CUDA 5.5 or higher\\r\\n    case NPP_BAD_ARGUMENT_ERROR:\\r\\n      return \"NPP_BAD_ARGUMENT_ERROR\";\\r\\n\\r\\n    case NPP_COEFFICIENT_ERROR:\\r\\n      return \"NPP_COEFFICIENT_ERROR\";\\r\\n\\r\\n    case NPP_RECTANGLE_ERROR:\\r\\n      return \"NPP_RECTANGLE_ERROR\";\\r\\n\\r\\n    case NPP_QUADRANGLE_ERROR:\\r\\n      return \"NPP_QUADRANGLE_ERROR\";\\r\\n\\r\\n    case NPP_MEMORY_ALLOCATION_ERR:\\r\\n      return \"NPP_MEMORY_ALLOCATION_ERROR\";\\r\\n\\r\\n    case NPP_HISTOGRAM_NUMBER_OF_LEVELS_ERROR:\\r\\n      return \"NPP_HISTOGRAM_NUMBER_OF_LEVELS_ERROR\";\\r\\n\\r\\n    case NPP_INVALID_HOST_POINTER_ERROR:\\r\\n      return \"NPP_INVALID_HOST_POINTER_ERROR\";\\r\\n\\r\\n    case NPP_INVALID_DEVICE_POINTER_ERROR:\\r\\n      return \"NPP_INVALID_DEVICE_POINTER_ERROR\";\\r\\n#endif\\r\\n\\r\\n    case NPP_LUT_NUMBER_OF_LEVELS_ERROR:\\r\\n      return \"NPP_LUT_NUMBER_OF_LEVELS_ERROR\";\\r\\n\\r\\n    case NPP_TEXTURE_BIND_ERROR:\\r\\n      return \"NPP_TEXTURE_BIND_ERROR\";\\r\\n\\r\\n    case NPP_WRONG_INTERSECTION_ROI_ERROR:\\r\\n      return \"NPP_WRONG_INTERSECTION_ROI_ERROR\";\\r\\n\\r\\n    case NPP_NOT_EVEN_STEP_ERROR:\\r\\n      return \"NPP_NOT_EVEN_STEP_ERROR\";\\r\\n\\r\\n    case NPP_INTERPOLATION_ERROR:\\r\\n      return \"NPP_INTERPOLATION_ERROR\";\\r\\n\\r\\n    case NPP_RESIZE_FACTOR_ERROR:\\r\\n      return \"NPP_RESIZE_FACTOR_ERROR\";\\r\\n\\r\\n    case NPP_HAAR_CLASSIFIER_PIXEL_MATCH_ERROR:\\r\\n      return \"NPP_HAAR_CLASSIFIER_PIXEL_MATCH_ERROR\";\\r\\n\\r\\n#if ((NPP_VERSION_MAJOR << 12) + (NPP_VERSION_MINOR << 4)) <= 0x5000\\r\\n\\r\\n    case NPP_MEMFREE_ERR:\\r\\n      return \"NPP_MEMFREE_ERR\";\\r\\n\\r\\n    case NPP_MEMSET_ERR:\\r\\n      return \"NPP_MEMSET_ERR\";\\r\\n\\r\\n    case NPP_MEMCPY_ERR:\\r\\n      return \"NPP_MEMCPY_ERROR\";\\r\\n\\r\\n    case NPP_MIRROR_FLIP_ERR:\\r\\n      return \"NPP_MIRROR_FLIP_ERR\";\\r\\n#else\\r\\n\\r\\n    case NPP_MEMFREE_ERROR:\\r\\n      return \"NPP_MEMFREE_ERROR\";\\r\\n\\r\\n    case NPP_MEMSET_ERROR:\\r\\n      return \"NPP_MEMSET_ERROR\";\\r\\n\\r\\n    case NPP_MEMCPY_ERROR:\\r\\n      return \"NPP_MEMCPY_ERROR\";\\r\\n\\r\\n    case NPP_MIRROR_FLIP_ERROR:\\r\\n      return \"NPP_MIRROR_FLIP_ERROR\";\\r\\n#endif\\r\\n\\r\\n    case NPP_ALIGNMENT_ERROR:\\r\\n      return \"NPP_ALIGNMENT_ERROR\";\\r\\n\\r\\n    case NPP_STEP_ERROR:\\r\\n      return \"NPP_STEP_ERROR\";\\r\\n\\r\\n    case NPP_SIZE_ERROR:\\r\\n      return \"NPP_SIZE_ERROR\";\\r\\n\\r\\n    case NPP_NULL_POINTER_ERROR:\\r\\n      return \"NPP_NULL_POINTER_ERROR\";\\r\\n\\r\\n    case NPP_CUDA_KERNEL_EXECUTION_ERROR:\\r\\n      return \"NPP_CUDA_KERNEL_EXECUTION_ERROR\";\\r\\n\\r\\n    case NPP_NOT_IMPLEMENTED_ERROR:\\r\\n      return \"NPP_NOT_IMPLEMENTED_ERROR\";\\r\\n\\r\\n    case NPP_ERROR:\\r\\n      return \"NPP_ERROR\";\\r\\n\\r\\n    case NPP_SUCCESS:\\r\\n      return \"NPP_SUCCESS\";\\r\\n\\r\\n    case NPP_WRONG_INTERSECTION_QUAD_WARNING:\\r\\n      return \"NPP_WRONG_INTERSECTION_QUAD_WARNING\";\\r\\n\\r\\n    case NPP_MISALIGNED_DST_ROI_WARNING:\\r\\n      return \"NPP_MISALIGNED_DST_ROI_WARNING\";\\r\\n\\r\\n    case NPP_AFFINE_QUAD_INCORRECT_WARNING:\\r\\n      return \"NPP_AFFINE_QUAD_INCORRECT_WARNING\";\\r\\n\\r\\n    case NPP_DOUBLE_SIZE_WARNING:\\r\\n      return \"NPP_DOUBLE_SIZE_WARNING\";\\r\\n\\r\\n    case NPP_WRONG_INTERSECTION_ROI_WARNING:\\r\\n      return \"NPP_WRONG_INTERSECTION_ROI_WARNING\";\\r\\n\\r\\n#if ((NPP_VERSION_MAJOR << 12) + (NPP_VERSION_MINOR << 4)) >= 0x6000\\r\\n    /* These are 6.0 or higher */\\r\\n    case NPP_LUT_PALETTE_BITSIZE_ERROR:\\r\\n      return \"NPP_LUT_PALETTE_BITSIZE_ERROR\";\\r\\n\\r\\n    case NPP_ZC_MODE_NOT_SUPPORTED_ERROR:\\r\\n      return \"NPP_ZC_MODE_NOT_SUPPORTED_ERROR\";\\r\\n\\r\\n    case NPP_QUALITY_INDEX_ERROR:\\r\\n      return \"NPP_QUALITY_INDEX_ERROR\";\\r\\n\\r\\n    case NPP_CHANNEL_ORDER_ERROR:\\r\\n      return \"NPP_CHANNEL_ORDER_ERROR\";\\r\\n\\r\\n    case NPP_ZERO_MASK_VALUE_ERROR:\\r\\n      return \"NPP_ZERO_MASK_VALUE_ERROR\";\\r\\n\\r\\n    case NPP_NUMBER_OF_CHANNELS_ERROR:\\r\\n      return \"NPP_NUMBER_OF_CHANNELS_ERROR\";\\r\\n\\r\\n    case NPP_COI_ERROR:\\r\\n      return \"NPP_COI_ERROR\";\\r\\n\\r\\n    case NPP_DIVISOR_ERROR:\\r\\n      return \"NPP_DIVISOR_ERROR\";\\r\\n\\r\\n    case NPP_CHANNEL_ERROR:\\r\\n      return \"NPP_CHANNEL_ERROR\";\\r\\n\\r\\n    case NPP_STRIDE_ERROR:\\r\\n      return \"NPP_STRIDE_ERROR\";\\r\\n\\r\\n    case NPP_ANCHOR_ERROR:\\r\\n      return \"NPP_ANCHOR_ERROR\";\\r\\n\\r\\n    case NPP_MASK_SIZE_ERROR:\\r\\n      return \"NPP_MASK_SIZE_ERROR\";\\r\\n\\r\\n    case NPP_MOMENT_00_ZERO_ERROR:\\r\\n      return \"NPP_MOMENT_00_ZERO_ERROR\";\\r\\n\\r\\n    case NPP_THRESHOLD_NEGATIVE_LEVEL_ERROR:\\r\\n      return \"NPP_THRESHOLD_NEGATIVE_LEVEL_ERROR\";\\r\\n\\r\\n    case NPP_THRESHOLD_ERROR:\\r\\n      return \"NPP_THRESHOLD_ERROR\";\\r\\n\\r\\n    case NPP_CONTEXT_MATCH_ERROR:\\r\\n      return \"NPP_CONTEXT_MATCH_ERROR\";\\r\\n\\r\\n    case NPP_FFT_FLAG_ERROR:\\r\\n      return \"NPP_FFT_FLAG_ERROR\";\\r\\n\\r\\n    case NPP_FFT_ORDER_ERROR:\\r\\n      return \"NPP_FFT_ORDER_ERROR\";\\r\\n\\r\\n    case NPP_SCALE_RANGE_ERROR:\\r\\n      return \"NPP_SCALE_RANGE_ERROR\";\\r\\n\\r\\n    case NPP_DATA_TYPE_ERROR:\\r\\n      return \"NPP_DATA_TYPE_ERROR\";\\r\\n\\r\\n    case NPP_OUT_OFF_RANGE_ERROR:\\r\\n      return \"NPP_OUT_OFF_RANGE_ERROR\";\\r\\n\\r\\n    case NPP_DIVIDE_BY_ZERO_ERROR:\\r\\n      return \"NPP_DIVIDE_BY_ZERO_ERROR\";\\r\\n\\r\\n    case NPP_RANGE_ERROR:\\r\\n      return \"NPP_RANGE_ERROR\";\\r\\n\\r\\n    case NPP_NO_MEMORY_ERROR:\\r\\n      return \"NPP_NO_MEMORY_ERROR\";\\r\\n\\r\\n    case NPP_ERROR_RESERVED:\\r\\n      return \"NPP_ERROR_RESERVED\";\\r\\n\\r\\n    case NPP_NO_OPERATION_WARNING:\\r\\n      return \"NPP_NO_OPERATION_WARNING\";\\r\\n\\r\\n    case NPP_DIVIDE_BY_ZERO_WARNING:\\r\\n      return \"NPP_DIVIDE_BY_ZERO_WARNING\";\\r\\n#endif\\r\\n\\r\\n#if ((NPP_VERSION_MAJOR << 12) + (NPP_VERSION_MINOR << 4)) >= 0x7000\\r\\n    /* These are 7.0 or higher */\\r\\n    case NPP_OVERFLOW_ERROR:\\r\\n      return \"NPP_OVERFLOW_ERROR\";\\r\\n\\r\\n    case NPP_CORRUPTED_DATA_ERROR:\\r\\n      return \"NPP_CORRUPTED_DATA_ERROR\";\\r\\n#endif\\r\\n  }\\r\\n\\r\\n  return \"<unknown>\";\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifdef __DRIVER_TYPES_H__\\r\\n#ifndef DEVICE_RESET\\r\\n#define DEVICE_RESET cudaDeviceReset();\\r\\n#endif\\r\\n#else\\r\\n#ifndef DEVICE_RESET\\r\\n#define DEVICE_RESET\\r\\n#endif\\r\\n#endif\\r\\n\\r\\ntemplate <typename T>\\r\\nvoid check(T result, char const *const func, const char *const file,\\r\\n           int const line) {\\r\\n  if (result) {\\r\\n    fprintf(stderr, \"CUDA error at %s:%d code=%d(%s) \\\\\"%s\\\\\" \\\\n\", file, line,\\r\\n            static_cast<unsigned int>(result), _cudaGetErrorEnum(result), func);\\r\\n    DEVICE_RESET\\r\\n    // Make sure we call CUDA Device Reset before exiting\\r\\n    exit(EXIT_FAILURE);\\r\\n  }\\r\\n}\\r\\n\\r\\n#ifdef __DRIVER_TYPES_H__\\r\\n// This will output the proper CUDA error strings in the event\\r\\n// that a CUDA host call returns an error\\r\\n#define checkCudaErrors(val) check((val), #val, __FILE__, __LINE__)\\r\\n\\r\\n// This will output the proper error string when calling cudaGetLastError\\r\\n#define getLastCudaError(msg) __getLastCudaError(msg, __FILE__, __LINE__)\\r\\n\\r\\ninline void __getLastCudaError(const char *errorMessage, const char *file,\\r\\n                               const int line) {\\r\\n  cudaError_t err = cudaGetLastError();\\r\\n\\r\\n  if (cudaSuccess != err) {\\r\\n    fprintf(stderr,\\r\\n            \"%s(%i) : getLastCudaError() CUDA error :\"\\r\\n            \" %s : (%d) %s.\\\\n\",\\r\\n            file, line, errorMessage, static_cast<int>(err),\\r\\n            cudaGetErrorString(err));\\r\\n    DEVICE_RESET\\r\\n    exit(EXIT_FAILURE);\\r\\n  }\\r\\n}\\r\\n\\r\\n// This will only print the proper error string when calling cudaGetLastError\\r\\n// but not exit program incase error detected.\\r\\n#define printLastCudaError(msg) __printLastCudaError(msg, __FILE__, __LINE__)\\r\\n\\r\\ninline void __printLastCudaError(const char *errorMessage, const char *file,\\r\\n                                 const int line) {\\r\\n  cudaError_t err = cudaGetLastError();\\r\\n\\r\\n  if (cudaSuccess != err) {\\r\\n    fprintf(stderr,\\r\\n            \"%s(%i) : getLastCudaError() CUDA error :\"\\r\\n            \" %s : (%d) %s.\\\\n\",\\r\\n            file, line, errorMessage, static_cast<int>(err),\\r\\n            cudaGetErrorString(err));\\r\\n  }\\r\\n}\\r\\n#endif\\r\\n\\r\\n#ifndef MAX\\r\\n#define MAX(a, b) (a > b ? a : b)\\r\\n#endif\\r\\n\\r\\n// Float To Int conversion\\r\\ninline int ftoi(float value) {\\r\\n  return (value >= 0 ? static_cast<int>(value + 0.5)\\r\\n                     : static_cast<int>(value - 0.5));\\r\\n}\\r\\n\\r\\n// Beginning of GPU Architecture definitions\\r\\ninline int _ConvertSMVer2Cores(int major, int minor) {\\r\\n  // Defines for GPU Architecture types (using the SM version to determine\\r\\n  // the # of cores per SM\\r\\n  typedef struct {\\r\\n    int SM;  // 0xMm (hexidecimal notation), M = SM Major version,\\r\\n    // and m = SM minor version\\r\\n    int Cores;\\r\\n  } sSMtoCores;\\r\\n\\r\\n  sSMtoCores nGpuArchCoresPerSM[] = {\\r\\n      {0x30, 192},\\r\\n      {0x32, 192},\\r\\n      {0x35, 192},\\r\\n      {0x37, 192},\\r\\n      {0x50, 128},\\r\\n      {0x52, 128},\\r\\n      {0x53, 128},\\r\\n      {0x60,  64},\\r\\n      {0x61, 128},\\r\\n      {0x62, 128},\\r\\n      {0x70,  64},\\r\\n      {0x72,  64},\\r\\n      {0x75,  64},\\r\\n      {-1, -1}};\\r\\n\\r\\n  int index = 0;\\r\\n\\r\\n  while (nGpuArchCoresPerSM[index].SM != -1) {\\r\\n    if (nGpuArchCoresPerSM[index].SM == ((major << 4) + minor)) {\\r\\n      return nGpuArchCoresPerSM[index].Cores;\\r\\n    }\\r\\n\\r\\n    index++;\\r\\n  }\\r\\n\\r\\n  // If we don\\'t find the values, we default use the previous one\\r\\n  // to run properly\\r\\n  printf(\\r\\n      \"MapSMtoCores for SM %d.%d is undefined.\"\\r\\n      \"  Default to use %d Cores/SM\\\\n\",\\r\\n      major, minor, nGpuArchCoresPerSM[index - 1].Cores);\\r\\n  return nGpuArchCoresPerSM[index - 1].Cores;\\r\\n}\\r\\n  // end of GPU Architecture definitions\\r\\n\\r\\n#ifdef __CUDA_RUNTIME_H__\\r\\n// General GPU Device CUDA Initialization\\r\\ninline int gpuDeviceInit(int devID) {\\r\\n  int device_count;\\r\\n  checkCudaErrors(cudaGetDeviceCount(&device_count));\\r\\n\\r\\n  if (device_count == 0) {\\r\\n    fprintf(stderr,\\r\\n            \"gpuDeviceInit() CUDA error: \"\\r\\n            \"no devices supporting CUDA.\\\\n\");\\r\\n    exit(EXIT_FAILURE);\\r\\n  }\\r\\n\\r\\n  if (devID < 0) {\\r\\n    devID = 0;\\r\\n  }\\r\\n\\r\\n  if (devID > device_count - 1) {\\r\\n    fprintf(stderr, \"\\\\n\");\\r\\n    fprintf(stderr, \">> %d CUDA capable GPU device(s) detected. <<\\\\n\",\\r\\n            device_count);\\r\\n    fprintf(stderr,\\r\\n            \">> gpuDeviceInit (-device=%d) is not a valid\"\\r\\n            \" GPU device. <<\\\\n\",\\r\\n            devID);\\r\\n    fprintf(stderr, \"\\\\n\");\\r\\n    return -devID;\\r\\n  }\\r\\n\\r\\n  cudaDeviceProp deviceProp;\\r\\n  checkCudaErrors(cudaGetDeviceProperties(&deviceProp, devID));\\r\\n\\r\\n  if (deviceProp.computeMode == cudaComputeModeProhibited) {\\r\\n    fprintf(stderr,\\r\\n            \"Error: device is running in <Compute Mode \"\\r\\n            \"Prohibited>, no threads can use cudaSetDevice().\\\\n\");\\r\\n    return -1;\\r\\n  }\\r\\n\\r\\n  if (deviceProp.major < 1) {\\r\\n    fprintf(stderr, \"gpuDeviceInit(): GPU device does not support CUDA.\\\\n\");\\r\\n    exit(EXIT_FAILURE);\\r\\n  }\\r\\n\\r\\n  checkCudaErrors(cudaSetDevice(devID));\\r\\n  printf(\"gpuDeviceInit() CUDA Device [%d]: \\\\\"%s\\\\n\", devID, deviceProp.name);\\r\\n\\r\\n  return devID;\\r\\n}\\r\\n\\r\\n// This function returns the best GPU (with maximum GFLOPS)\\r\\ninline int gpuGetMaxGflopsDeviceId() {\\r\\n  int current_device = 0, sm_per_multiproc = 0;\\r\\n  int max_perf_device = 0;\\r\\n  int device_count = 0;\\r\\n  int devices_prohibited = 0;\\r\\n\\r\\n  uint64_t max_compute_perf = 0;\\r\\n  cudaDeviceProp deviceProp;\\r\\n  checkCudaErrors(cudaGetDeviceCount(&device_count));\\r\\n\\r\\n  if (device_count == 0) {\\r\\n    fprintf(stderr,\\r\\n            \"gpuGetMaxGflopsDeviceId() CUDA error:\"\\r\\n            \" no devices supporting CUDA.\\\\n\");\\r\\n    exit(EXIT_FAILURE);\\r\\n  }\\r\\n\\r\\n  // Find the best CUDA capable GPU device\\r\\n  current_device = 0;\\r\\n\\r\\n  while (current_device < device_count) {\\r\\n    cudaGetDeviceProperties(&deviceProp, current_device);\\r\\n\\r\\n    // If this GPU is not running on Compute Mode prohibited,\\r\\n    // then we can add it to the list\\r\\n    if (deviceProp.computeMode != cudaComputeModeProhibited) {\\r\\n      if (deviceProp.major == 9999 && deviceProp.minor == 9999) {\\r\\n        sm_per_multiproc = 1;\\r\\n      } else {\\r\\n        sm_per_multiproc =\\r\\n            _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor);\\r\\n      }\\r\\n\\r\\n      uint64_t compute_perf = (uint64_t)deviceProp.multiProcessorCount *\\r\\n                              sm_per_multiproc * deviceProp.clockRate;\\r\\n\\r\\n      if (compute_perf > max_compute_perf) {\\r\\n        max_compute_perf = compute_perf;\\r\\n        max_perf_device = current_device;\\r\\n      }\\r\\n    } else {\\r\\n      devices_prohibited++;\\r\\n    }\\r\\n\\r\\n    ++current_device;\\r\\n  }\\r\\n\\r\\n  if (devices_prohibited == device_count) {\\r\\n    fprintf(stderr,\\r\\n            \"gpuGetMaxGflopsDeviceId() CUDA error:\"\\r\\n            \" all devices have compute mode prohibited.\\\\n\");\\r\\n    exit(EXIT_FAILURE);\\r\\n  }\\r\\n\\r\\n  return max_perf_device;\\r\\n}\\r\\n\\r\\n// Initialization code to find the best CUDA Device\\r\\ninline int findCudaDevice(int argc, const char **argv) {\\r\\n  cudaDeviceProp deviceProp;\\r\\n  int devID = 0;\\r\\n\\r\\n  // If the command-line has a device number specified, use it\\r\\n  if (checkCmdLineFlag(argc, argv, \"device\")) {\\r\\n    devID = getCmdLineArgumentInt(argc, argv, \"device=\");\\r\\n\\r\\n    if (devID < 0) {\\r\\n      printf(\"Invalid command line parameter\\\\n \");\\r\\n      exit(EXIT_FAILURE);\\r\\n    } else {\\r\\n      devID = gpuDeviceInit(devID);\\r\\n\\r\\n      if (devID < 0) {\\r\\n        printf(\"exiting...\\\\n\");\\r\\n        exit(EXIT_FAILURE);\\r\\n      }\\r\\n    }\\r\\n  } else {\\r\\n    // Otherwise pick the device with highest Gflops/s\\r\\n    devID = gpuGetMaxGflopsDeviceId();\\r\\n    checkCudaErrors(cudaSetDevice(devID));\\r\\n    checkCudaErrors(cudaGetDeviceProperties(&deviceProp, devID));\\r\\n    printf(\"GPU Device %d: \\\\\"%s\\\\\" with compute capability %d.%d\\\\n\\\\n\", devID,\\r\\n           deviceProp.name, deviceProp.major, deviceProp.minor);\\r\\n  }\\r\\n\\r\\n  return devID;\\r\\n}\\r\\n\\r\\ninline int findIntegratedGPU() {\\r\\n  int current_device = 0;\\r\\n  int device_count = 0;\\r\\n  int devices_prohibited = 0;\\r\\n\\r\\n  cudaDeviceProp deviceProp;\\r\\n  checkCudaErrors(cudaGetDeviceCount(&device_count));\\r\\n\\r\\n  if (device_count == 0) {\\r\\n    fprintf(stderr, \"CUDA error: no devices supporting CUDA.\\\\n\");\\r\\n    exit(EXIT_FAILURE);\\r\\n  }\\r\\n\\r\\n  // Find the integrated GPU which is compute capable\\r\\n  while (current_device < device_count) {\\r\\n    cudaGetDeviceProperties(&deviceProp, current_device);\\r\\n\\r\\n    // If GPU is integrated and is not running on Compute Mode prohibited,\\r\\n    // then cuda can map to GLES resource\\r\\n    if (deviceProp.integrated &&\\r\\n        (deviceProp.computeMode != cudaComputeModeProhibited)) {\\r\\n      checkCudaErrors(cudaSetDevice(current_device));\\r\\n      checkCudaErrors(cudaGetDeviceProperties(&deviceProp, current_device));\\r\\n      printf(\"GPU Device %d: \\\\\"%s\\\\\" with compute capability %d.%d\\\\n\\\\n\",\\r\\n             current_device, deviceProp.name, deviceProp.major,\\r\\n             deviceProp.minor);\\r\\n\\r\\n      return current_device;\\r\\n    } else {\\r\\n      devices_prohibited++;\\r\\n    }\\r\\n\\r\\n    current_device++;\\r\\n  }\\r\\n\\r\\n  if (devices_prohibited == device_count) {\\r\\n    fprintf(stderr,\\r\\n            \"CUDA error:\"\\r\\n            \" No GLES-CUDA Interop capable GPU found.\\\\n\");\\r\\n    exit(EXIT_FAILURE);\\r\\n  }\\r\\n\\r\\n  return -1;\\r\\n}\\r\\n\\r\\n// General check for CUDA GPU SM Capabilities\\r\\ninline bool checkCudaCapabilities(int major_version, int minor_version) {\\r\\n  cudaDeviceProp deviceProp;\\r\\n  deviceProp.major = 0;\\r\\n  deviceProp.minor = 0;\\r\\n  int dev;\\r\\n\\r\\n  checkCudaErrors(cudaGetDevice(&dev));\\r\\n  checkCudaErrors(cudaGetDeviceProperties(&deviceProp, dev));\\r\\n\\r\\n  if ((deviceProp.major > major_version) ||\\r\\n      (deviceProp.major == major_version &&\\r\\n       deviceProp.minor >= minor_version)) {\\r\\n    printf(\"  Device %d: <%16s >, Compute SM %d.%d detected\\\\n\", dev,\\r\\n           deviceProp.name, deviceProp.major, deviceProp.minor);\\r\\n    return true;\\r\\n  } else {\\r\\n    printf(\\r\\n        \"  No GPU device was found that can support \"\\r\\n        \"CUDA compute capability %d.%d.\\\\n\",\\r\\n        major_version, minor_version);\\r\\n    return false;\\r\\n  }\\r\\n}\\r\\n#endif\\r\\n\\r\\n  // end of CUDA Helper Functions\\r\\n\\r\\n#endif  // COMMON_HELPER_CUDA_H_'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "riz_rzqcjqqe",
        "outputId": "177f3306-1745-4b09-f4eb-f52bc2b17a4b"
      },
      "source": [
        "from IPython.display import Markdown as md\r\n",
        "f = open('cuda_pricing.cu', 'r')\r\n",
        "md(\"\"\"```C\r\n",
        "%s\r\n",
        "   ```\"\"\" % (f.read()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/markdown": "```C\n#include <vector>\n#include <stdio.h>\n#include <iostream>\n#include <chrono>\n#include <cuda_runtime.h>\n#include <helper_cuda.h>\n#include <curand.h>\n \n#define CHECKCURAND(expression)                         \\\n  {                                                     \\\n    curandStatus_t status = (expression);                         \\\n    if (status != CURAND_STATUS_SUCCESS) {                        \\\n      std::cerr << \"Curand Error on line \" << __LINE__<< std::endl;     \\\n      std::exit(EXIT_FAILURE);                                          \\\n    }                                                                   \\\n  }\n\n// atomicAdd is introduced for compute capability >=6.0\n#if !defined(__CUDA_ARCH__) || __CUDA_ARCH__ >= 600\n#else\n__device__ double atomicAdd(double* address, double val)\n{\n      printf(\"device arch <=600\\n\");\n        unsigned long long int* address_as_ull = (unsigned long long int*)address;\n          unsigned long long int old = *address_as_ull, assumed;\n            do {\n                    assumed = old;\n                        old = atomicCAS(address_as_ull, assumed,\n                                                    __double_as_longlong(val + __longlong_as_double(assumed)));\n                          } while (assumed != old);\n              return __longlong_as_double(old);\n}\n#endif\n\n__global__ void sumPayoffKernel(float *d_s, const unsigned N_PATHS, double *mysum)\n{\n  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n  unsigned stride = blockDim.x * gridDim.x;\n  unsigned tid = threadIdx.x;\n\n  extern __shared__ double smdata[];\n  smdata[tid] = 0.0;\n\n  for (unsigned i = idx; i<N_PATHS; i+=stride)\n  {\n    smdata[tid] += (double) d_s[i];\n  }\n\n  for (unsigned s=blockDim.x/2; s>0; s>>=1)\n  {\n    __syncthreads();\n    if (tid < s) smdata[tid] += smdata[tid + s];\n  }\n\n  if (tid == 0)\n  {\n    atomicAdd(mysum, smdata[0]);\n  }\n}\n\n__global__ void barrier_option(\n    float *d_s,\n    const float T,\n    const float K,\n    const float B,\n    const float S0,\n    const float sigma,\n    const float mu,\n    const float r,\n    const float * d_normals,\n    const long N_STEPS,\n    const long N_PATHS)\n{\n  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n  unsigned stride = blockDim.x * gridDim.x;\n  const float tmp1 = mu*T/N_STEPS;\n  const float tmp2 = exp(-r*T);\n  const float tmp3 = sqrt(T/N_STEPS);\n  double running_average = 0.0;\n\n  for (unsigned i = idx; i<N_PATHS; i+=stride)\n  {\n    float s_curr = S0;\n    for(unsigned n = 0; n < N_STEPS; n++){\n       s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS];\n       running_average += (s_curr - running_average) / (n + 1.0) ;\n       if (running_average <= B){\n           break;\n       }\n    }\n\n    float payoff = (running_average>K ? running_average-K : 0.f);\n    d_s[i] = tmp2 * payoff;\n  }\n}\n\nint main(int argc, char *argv[]) {\n  try {\n    // declare variables and constants\n    size_t N_PATHS = 8192000;\n    size_t N_STEPS = 365;\n    if (argc >= 2)  N_PATHS = atoi(argv[1]);\n\n    if (argc >= 3)  N_STEPS = atoi(argv[2]);\n\n    const float T = 1.0f;\n    const float K = 110.0f;\n    const float B = 100.0f;\n    const float S0 = 120.0f;\n    const float sigma = 0.35f;\n    const float mu = 0.1f;\n    const float r = 0.05f;\n\n\n    double gpu_sum{0.0};\n\n    int devID{0};\n    cudaDeviceProp deviceProps;\n\n    checkCudaErrors(cudaGetDeviceProperties(&deviceProps, devID));\n    printf(\"CUDA device [%s]\\n\", deviceProps.name);\n    printf(\"GPU Device %d: \\\"%s\\\" with compute capability %d.%d\\n\\n\", devID, deviceProps.name, deviceProps.major, deviceProps.minor);\n    // Generate random numbers on the device\n    curandGenerator_t curandGenerator;\n    CHECKCURAND(curandCreateGenerator(&curandGenerator, CURAND_RNG_PSEUDO_MTGP32));\n    CHECKCURAND(curandSetPseudoRandomGeneratorSeed(curandGenerator, 1234ULL)) ;\n\n    const size_t N_NORMALS = (size_t)N_STEPS * N_PATHS;\n    float *d_normals;\n    checkCudaErrors(cudaMalloc(&d_normals, N_NORMALS * sizeof(float)));\n    CHECKCURAND(curandGenerateNormal(curandGenerator, d_normals, N_NORMALS, 0.0f, 1.0f));\n    cudaDeviceSynchronize();\n\n  \t// before kernel launch, check the max potential blockSize\n  \tint BLOCK_SIZE, GRID_SIZE;\n  \tcheckCudaErrors(cudaOccupancyMaxPotentialBlockSize(&GRID_SIZE,\n  \t                                                   &BLOCK_SIZE,\n  \t                                                   barrier_option,\n  \t                                                   0, N_PATHS));\n\n  \tstd::cout << \"suggested block size \" << BLOCK_SIZE\n  \t          << \" \\nsuggested grid size \" << GRID_SIZE\n  \t          << std::endl;\n\n  \tstd::cout << \"Used grid size \" << GRID_SIZE << std::endl;\n\n  \t// Kernel launch\n  \tauto t1=std::chrono::high_resolution_clock::now();\n\n  \tfloat *d_s;\n  \tcheckCudaErrors(cudaMalloc(&d_s, N_PATHS*sizeof(float)));\n\n  \tauto t3=std::chrono::high_resolution_clock::now();\n  \tbarrier_option<<<GRID_SIZE, BLOCK_SIZE>>>(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS);\n  \tcudaDeviceSynchronize();\n  \tauto t4=std::chrono::high_resolution_clock::now();\n\n  \tdouble* mySum;\n  \tcheckCudaErrors(cudaMallocManaged(&mySum, sizeof(double)));\n  \tsumPayoffKernel<<<GRID_SIZE, BLOCK_SIZE, BLOCK_SIZE*sizeof(double)>>>(d_s, N_PATHS, mySum);\n  \tcudaDeviceSynchronize();\n  \tauto t5=std::chrono::high_resolution_clock::now();\n\n  \tstd::cout << \"sumPayoffKernel takes \"\n  \t          << std::chrono::duration_cast<std::chrono::microseconds>(t5-t4).count() / 1000.f\n  \t          << \" ms\\n\";\n\n  \tgpu_sum = mySum[0] / N_PATHS;\n\n  \tauto t2=std::chrono::high_resolution_clock::now();\n\n  \t// clean up\n  \tCHECKCURAND(curandDestroyGenerator( curandGenerator )) ;\n  \tcheckCudaErrors(cudaFree(d_s));\n  \tcheckCudaErrors(cudaFree(d_normals));\n  \tcheckCudaErrors(cudaFree(mySum));\n\n  \tstd::cout << \"price \"\n              << gpu_sum\n              << \" time \"\n  \t          << std::chrono::duration_cast<std::chrono::microseconds>(t5-t1).count() / 1000.f\n  \t          << \" ms\\n\";\n  }\n\n  catch(std::\n        exception& e)\n  {\n    std::cout<< \"exception: \" << e.what() << \"\\n\";\n  }\n}\n   ```",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBTh8lMVjwLE",
        "outputId": "ebe770c1-154f-4cb0-e6ba-2ad78ddaf672"
      },
      "source": [
        "!make out\r\n",
        "!./out\r\n",
        "# !nvcc -O3 -gencode=arch=compute_37,code=sm_37 -gencode=arch=compute_37,code=compute_37 helper_cuda.h cuda_pricing.cu -o cudaa\r\n",
        "# !./cudaa"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make: *** No rule to make target 'out'.  Stop.\n",
            "/bin/bash: ./out: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFSx-6BmU6tP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "538e6837-7001-4a99-d6f0-3042120fdff9"
      },
      "source": [
        "import cupy\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import time\r\n",
        "import numba\r\n",
        "from numba import cuda\r\n",
        "from numba import njit\r\n",
        "from numba import prange\r\n",
        "#import cudf\r\n",
        "cupy.cuda.set_allocator(None)\r\n",
        "\r\n",
        "N_PATHS = 8192000\r\n",
        "N_STEPS = 365\r\n",
        "T = 1.0\r\n",
        "K = 110.0\r\n",
        "B = 100.0\r\n",
        "S0 = 120.0\r\n",
        "sigma = 0.35\r\n",
        "mu = 0.1\r\n",
        "r = 0.05"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-81d4e111cae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cupy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtFAz7lldQDT"
      },
      "source": [
        "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\r\n",
        "randoms_cpu = np_randoms = cupy.asnumpy(randoms_gpu)\r\n",
        "output =  np.zeros(N_PATHS, dtype=np.float32)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cr-RJj4ePwW"
      },
      "source": [
        "##Programa en CPU secuencial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "daX7r8o6dbX6",
        "outputId": "48fe962e-9575-46f4-f2a9-5b006a0e83f5"
      },
      "source": [
        "@njit(fastmath=True)\r\n",
        "def cpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\r\n",
        "    tmp1 = mu*T/N_STEPS\r\n",
        "    tmp2 = math.exp(-r*T)\r\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\r\n",
        "    running_average = 0.0\r\n",
        "    for i in range(N_PATHS):\r\n",
        "        s_curr = S0\r\n",
        "        for n in range(N_STEPS):\r\n",
        "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\r\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\r\n",
        "            if running_average <= B:\r\n",
        "                break\r\n",
        "\r\n",
        "        payoff = running_average - K if running_average>K else 0\r\n",
        "        d_s[i] = tmp2 * payoff"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-09754b3e2113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mnjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfastmath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcpu_barrier_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_normals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_PATHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtmp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'njit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3TLk7rdhEG",
        "outputId": "85c17a9e-9e07-4cb2-d0a7-645fff979719"
      },
      "source": [
        "cpu_barrier_option(output, np.float32(T), np.float32(K), \r\n",
        "                    np.float32(B), np.float32(S0), \r\n",
        "                    np.float32(sigma), np.float32(mu), \r\n",
        "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\r\n",
        "s = time.time()\r\n",
        "cpu_barrier_option(output, np.float32(T), np.float32(K), \r\n",
        "                    np.float32(B), np.float32(S0), \r\n",
        "                    np.float32(sigma), np.float32(mu), \r\n",
        "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\r\n",
        "v = output.mean()\r\n",
        "e = time.time()\r\n",
        "print('time', e-s, 'v', v)\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time 42.557671785354614 v 18.720213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmUfBPQpeWfA"
      },
      "source": [
        "##Programa en CPU en paralelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS7jx1-SefaG"
      },
      "source": [
        "@njit(fastmath=True, parallel=True)\r\n",
        "def cpu_multiplecore_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\r\n",
        "    tmp1 = mu*T/N_STEPS\r\n",
        "    tmp2 = math.exp(-r*T)\r\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\r\n",
        "    for i in prange(N_PATHS):\r\n",
        "        s_curr = S0\r\n",
        "        running_average = 0.0\r\n",
        "        for n in range(N_STEPS):\r\n",
        "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\r\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\r\n",
        "            if running_average <= B:\r\n",
        "                break\r\n",
        "        payoff = running_average - K if running_average>K else 0\r\n",
        "        d_s[i] = tmp2 * payoff\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LL7MgM6et_x",
        "outputId": "8fbed08e-03f0-45f2-cf85-be9c6edd9f67"
      },
      "source": [
        "cpu_multiplecore_barrier_option(output, np.float32(T), np.float32(K), \r\n",
        "                    np.float32(B), np.float32(S0), \r\n",
        "                    np.float32(sigma), np.float32(mu), \r\n",
        "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\r\n",
        "s = time.time()\r\n",
        "cpu_multiplecore_barrier_option(output, np.float32(T), np.float32(K), \r\n",
        "                    np.float32(B), np.float32(S0), \r\n",
        "                    np.float32(sigma), np.float32(mu), \r\n",
        "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\r\n",
        "v = output.mean()\r\n",
        "e = time.time()\r\n",
        "print('time', e-s, 'v', v)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time 37.503809690475464 v 18.706549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LOCozJieZuF"
      },
      "source": [
        "##Programa en GPU en paralelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSVPnxrgU63k"
      },
      "source": [
        "@cuda.jit\r\n",
        "def numba_gpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\r\n",
        "    # ii - overall thread index\r\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\r\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\r\n",
        "    tmp1 = mu*T/N_STEPS\r\n",
        "    tmp2 = math.exp(-r*T)\r\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\r\n",
        "    running_average = 0.0\r\n",
        "    for i in range(ii, N_PATHS, stride):\r\n",
        "        s_curr = S0\r\n",
        "        for n in range(N_STEPS):\r\n",
        "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\r\n",
        "            running_average += (s_curr - running_average) / (n + 1.0)\r\n",
        "            if running_average <= B:\r\n",
        "                break\r\n",
        "        payoff = running_average - K if running_average>K else 0\r\n",
        "        d_s[i] = tmp2 * payoff "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrhEuuk9b4ju",
        "outputId": "f1e1efb2-74e6-404b-fd52-49d2a3f09765"
      },
      "source": [
        "number_of_threads = 256\r\n",
        "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\r\n",
        "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\r\n",
        "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \r\n",
        "                    np.float32(B), np.float32(S0), \r\n",
        "                    np.float32(sigma), np.float32(mu), \r\n",
        "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\r\n",
        "s = time.time()\r\n",
        "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \r\n",
        "                    np.float32(B), np.float32(S0), \r\n",
        "                    np.float32(sigma), np.float32(mu), \r\n",
        "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\r\n",
        "v = output.mean()\r\n",
        "cuda.synchronize()\r\n",
        "e = time.time()\r\n",
        "print('time', e-s, 'v', v)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time 1.1581580638885498 v 18.711342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoboRbYhfHeI"
      },
      "source": [
        "##Programa GPU en paralelo con compartición de memoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYlJTSAWfLPi"
      },
      "source": [
        "@cuda.jit\r\n",
        "def numba_gpu_barrier_option_shared_mem(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\r\n",
        "    shared = cuda.shared.array(shape=0, dtype=numba.float32)\r\n",
        "    # load to shared memory\r\n",
        "    path_offset = cuda.blockIdx.x * cuda.blockDim.x\r\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\r\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\r\n",
        "    tmp1 = mu*T/N_STEPS\r\n",
        "    tmp2 = math.exp(-r*T)\r\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\r\n",
        "    running_average = 0.0\r\n",
        "    for i in range(ii, N_PATHS, stride):\r\n",
        "        s_curr = S0\r\n",
        "        for n in range(N_STEPS):\r\n",
        "            shared[cuda.threadIdx.x] = d_normals[path_offset + cuda.threadIdx.x + n * N_PATHS]\r\n",
        "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*shared[cuda.threadIdx.x]\r\n",
        "            running_average += (s_curr - running_average) / (n + 1.0)\r\n",
        "            if running_average <= B:\r\n",
        "                break\r\n",
        "        payoff = running_average - K if running_average>K else 0\r\n",
        "        d_s[i] = tmp2 * payoff\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wyRpHo9fMOt",
        "outputId": "a252bb76-fadb-4b88-dc9d-31010d3a736d"
      },
      "source": [
        "number_of_threads = 256\r\n",
        "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\r\n",
        "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\r\n",
        "shared_buffer_size = number_of_threads * 4\r\n",
        "numba_gpu_barrier_option_shared_mem[(number_of_blocks,), (number_of_threads,), 0, shared_buffer_size](output, np.float32(T), np.float32(K), \r\n",
        "                    np.float32(B), np.float32(S0), \r\n",
        "                    np.float32(sigma), np.float32(mu), \r\n",
        "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\r\n",
        "s = time.time()\r\n",
        "numba_gpu_barrier_option_shared_mem[(number_of_blocks,), (number_of_threads,), 0, shared_buffer_size](output, np.float32(T), np.float32(K), \r\n",
        "                    np.float32(B), np.float32(S0), \r\n",
        "                    np.float32(sigma), np.float32(mu), \r\n",
        "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\r\n",
        "v = output.mean()\r\n",
        "cuda.synchronize()\r\n",
        "e = time.time()\r\n",
        "print('time', e-s, 'v', v)\r\n",
        "\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time 0.3514516353607178 v 18.706553\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}