{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CudaNumbaParalelo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/Numerico2021/blob/desarrollo/08_MonteCarlo/CudaNumbaParalelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJmaX0Gets0u"
      },
      "source": [
        "#Programación en Numba-Cuda con python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXfJOpOItu22"
      },
      "source": [
        "CUDA tiene un modelo de ejecución diferente al modelo secuencial tradicional utilizado para programar CPU. En CUDA, el código que escriba será ejecutado por varios subprocesos a la vez (a menudo cientos o miles). Su solución se modelará definiendo una jerarquía de subprocesos de cuadrícula, bloques e subprocesos.\r\n",
        "\r\n",
        "El soporte CUDA de Numba expone las instalaciones para declarar y administrar esta jerarquía de subprocesos. Las instalaciones son muy similares a las expuestas por el lenguaje C CUDA de NVidia.\r\n",
        "\r\n",
        "Numba también expone tres tipos de memoria de GPU: memoria de dispositivo global (la memoria fuera del chip grande y relativamente lenta que está conectada a la GPU), memoria compartida en el chip y memoria local. Para todos los algoritmos, excepto los más simples, es importante que considere cuidadosamente cómo usar y acceder a la memoria para minimizar los requisitos de ancho de banda y la contención."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GALRqhRpue9q"
      },
      "source": [
        "##¿Qué es Numba?.\r\n",
        "\r\n",
        "Según la documentación de Numba, \"Numba es un compilador justo a tiempo para Python que funciona mejor en código que usa matrices y funciones de NumPy, y bucles. La forma más común de usar Numba es a través de su colección de decoradores que se pueden aplicar a sus funciones para indicarle a Numba que las compile. Cuando se realiza una llamada a una función decorada de Numba, se compila en código máquina \"justo a tiempo\" para su ejecución y todo o parte de su código puede ejecutarse posteriormente a la velocidad del código máquina nativo ! \"\r\n",
        "\r\n",
        "Para nuestros propósitos de hoy, Numba es un paquete de Python que le permite escribir código Python para GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkBX0-CvN2y"
      },
      "source": [
        "##Accediendo a la GPU\r\n",
        "\r\n",
        "1) Para ejecutar las funciones de Numba usando las GPU gratuitas de Google, tenemos que hacer un par de cosas. Primero, vaya al menú Runtime, haga clic en 'Cambiar tipo de tiempo de ejecución', y en el cuadro emergente, en 'Acelerador de hardware', seleccione 'GPU'. Guarde el tiempo de ejecución.\r\n",
        "\r\n",
        "2) Idealmente, eso es todo lo que deberíamos tener que hacer. Pero en la práctica, aunque las bibliotecas CUDA están instaladas, en el momento de escribir este artículo, Colab no puede encontrarlas automáticamente. Entonces, averiguaremos dónde están y luego le indicaremos a Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT2EQdkytuLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49ee8b8-c344-42af-bdbf-7cab5f5c4ab1"
      },
      "source": [
        "!find / -iname 'libdevice'\r\n",
        "!find / -iname 'libnvvm.so'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/nvvm/libdevice\n",
            "/usr/local/cuda-10.0/nvvm/libdevice\n",
            "/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n",
            "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGyfEtgUvf4k"
      },
      "source": [
        "Pegue la ubicación de las bibliotecas en el siguiente cuadro de código (si es diferente, de lo contrario, puede ejecutar el código):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYqtsk-Qj2rT"
      },
      "source": [
        "import os\r\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.0/nvvm/libdevice\"\r\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a1UNDfhvt1D"
      },
      "source": [
        "Importación de bibliotecas para realizar el código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEq5llWOj68-",
        "outputId": "fcadc002-7352-404b-8fcc-08573d139a4d"
      },
      "source": [
        "from numba import cuda\r\n",
        "import numba\r\n",
        "print(cuda.gpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Managed Device 0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9oKFWaNv24D"
      },
      "source": [
        "\" print(cuda.gpus) \" nos dice cuantas tarjetas GPU's tenemos disponibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7J7oOHfwBeM"
      },
      "source": [
        "##Declaración de Kernels.\r\n",
        "\r\n",
        "Una función del tipo **Kernel** es una función de GPU que debe llamarse desde el código de la CPU$^{1}$ . Esta tiene dos características fundamentales:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "1.   Los **Kernel** no pueden devolver explícitamente un valor; todos los datos de resultado deben escribirse en una matriz que se pasa a la función (si calcula un escalar, probablemente pasará una matriz de un elemento);\r\n",
        "2.   Los **Kernel** declaran explícitamente su jerarquía de subprocesos cuando se les llama: es decir, el número de bloques de subprocesos y el número de subprocesos por bloque (tenga en cuenta que, si bien un kernel se compila una vez, se puede llamar varias veces con diferentes tamaños de bloque o tamaños de grid).\r\n",
        "\r\n",
        "Nota (1): Los dispositivos CUDA más nuevos admiten el lanzamiento del kernel del lado del dispositivo; esta característica se llama paralelismo dinámico pero Numba no la admite actualmente)\r\n",
        "\r\n",
        "A primera vista, escribir un kernel CUDA con Numba se parece mucho a escribir una función JIT para la CPU: \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEUqOJIlkM7z"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    \"\"\"\r\n",
        "    Increment all array elements by one.\r\n",
        "    \"\"\"\r\n",
        "    # code elided here; read further for different implementations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diMNYgPlyRpk"
      },
      "source": [
        "##Lanzamiento de Kernels.\r\n",
        "\r\n",
        "Hay dos maneras usuales de lanzar un Kernel en numba. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygj-8o4w1dly"
      },
      "source": [
        "###Forma 1 de lanzar kernel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygDMwnRHytJj"
      },
      "source": [
        "griddim = 1, 2\r\n",
        "blockdim = 3, 4\r\n",
        "increment_by_one[griddim, blockdim](aryA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7RVlNnMzY5m"
      },
      "source": [
        "Que sería similar a cuando lanzas un **Kernel** en Cuda C.Cómo se puede apreciar a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6kIPyalzRE0"
      },
      "source": [
        "dim3 griddim(1, 2);\r\n",
        "dim3 blockdim(3, 4);\r\n",
        "increment_by_one<<<griddim, blockdim>>>(aryA);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvl1eyOWzriv"
      },
      "source": [
        "griddim es el número de bloques de subprocesos por grid. Puede ser:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Un entero.\r\n",
        "*   Una 1-tupla de enteros.\r\n",
        "*   Una 2-tupla de enteros.\r\n",
        "\r\n",
        "blockdim es el número de subprocesos por bloque. Puede ser:\r\n",
        "\r\n",
        "*   Un entero.\r\n",
        "*   Una 1-tupla de enteros.\r\n",
        "*   Una 2-tupla de enteros.\r\n",
        "*   Una 3-tupla de enteros.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0wk_R0f1j8Z"
      },
      "source": [
        "###Forma 2 de lanzar kernel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5KE6g-X1rFC"
      },
      "source": [
        "threadsperblock = 32\r\n",
        "blockspergrid = (an_array.size + (threadsperblock - 1)) // threadsperblock\r\n",
        "increment_by_one[blockspergrid, threadsperblock](an_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXcbpoM12b-"
      },
      "source": [
        "Note dos cosas:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Cree una instancia del kernel propiamente dicho, especificando un número de bloques (o \"bloques por cuadrícula\") y un número de subprocesos por bloque. El producto de los dos dará el número total de hilos lanzados. La instanciación del kernel se realiza tomando la función del kernel compilada (aquí increment_by_one) e indexándola con una tupla de enteros.\r\n",
        "*   Ejecutando el kernel, pasándole la matriz de entrada (y cualquier matriz de salida separada si es necesario). Por defecto, ejecutar un kernel es sincrónico: la función regresa cuando el kernel ha terminado de ejecutarse y los datos se vuelven a sincronizar.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAv0ahrI4GSU"
      },
      "source": [
        "###Forma 3 de lanzar Kernel.\r\n",
        "\r\n",
        "En ocasiones queremos ser específicos con los datos que enviamos a los Kernel, debido a eso, a los decoradores de Numba les podemos pasar el tipo de dato que se procesará. Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A-W6bWG4gIY"
      },
      "source": [
        "@cuda.jit('void(int32[:], int32[:])')\r\n",
        "def foo(aryA, aryB):\r\n",
        "    \" Process some data \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z2aGgcA4oIg"
      },
      "source": [
        "En la función anterior, le decimos al programa que ingresamos dos 1D-arreglos de tipo entero ( int32[:] , int32[:] ) y extraemos ninguna información ( void ).\r\n",
        "\r\n",
        "También podemos lanzar un kernel, extrayendo algún dato, como se visualiza a continuación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwH-Gtne5P3t"
      },
      "source": [
        "@cuda.jit('int32(int32, int32)', device=True)\r\n",
        "def bar(a, b):\r\n",
        "    \" here computes the sum \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfSEIO685V0n"
      },
      "source": [
        "En la función anterior, le decimos al programa que ingresamos dos datos de tipo entero ( int32 , int32 ) y extraemosotro dato de tipo entero ( int32 )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8WVrsgH5nvf"
      },
      "source": [
        "@cuda.jit('void(int32[:], int32[:], int32[:])')\r\n",
        "def use_bar(aryA, aryB, aryOut):\r\n",
        "    i = cuda.grid(1) # global position of the thread for a 1D grid.\r\n",
        "    aryOut[i] = bar(aryA[i], aryB[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g5DB0rO503r"
      },
      "source": [
        "##Tamaño del bloque.\r\n",
        "\r\n",
        "Puede parecer curioso tener una jerarquía de dos niveles al declarar el número de subprocesos que necesita un Kernel. El tamaño del bloque (es decir, el número de subprocesos por bloque) suele ser crucial:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   En el lado del software, el tamaño del bloque determina cuántos subprocesos comparten un área determinada de memoria compartida.\r\n",
        "*   En el lado del hardware, el tamaño del bloque debe ser lo suficientemente grande para la ocupación completa de las unidades de ejecución; Las recomendaciones se pueden encontrar en la Guía de programación CUDA C\r\n",
        "\r\n",
        "Para ayudar a lidiar con matrices multidimensionales, CUDA le permite especificar bloques y cuadrículas multidimensionales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gcrIb707Jmo"
      },
      "source": [
        "##Posición del Hilo (Subproceso).\r\n",
        "\r\n",
        "Cuando se ejecuta un kernel, el código de la función del kernel es ejecutado por cada hilo una vez. Por lo tanto, tiene que saber en qué hilo se encuentra, para saber de qué elemento (s) de la matriz es responsable (los algoritmos complejos pueden definir responsabilidades más complejas, pero el principio subyacente es el mismo).\r\n",
        "\r\n",
        "Una forma es que el hilo determine su posición en la grid y en el bloque y calcule manualmente la posición de la matriz correspondiente:\r\n",
        "\r\n",
        "Para un 1D grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRXXD4--70Q_"
      },
      "source": [
        "tx = cuda.threadIdx.x\r\n",
        "bx = cuda.blockIdx.x\r\n",
        "bw = cuda.blockDim.x\r\n",
        "i = tx + bx * bw\r\n",
        "array[i] = something(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrR9LgKH72zy"
      },
      "source": [
        "Para un 2d grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm9949TF76so"
      },
      "source": [
        "tx = cuda.threadIdx.x\r\n",
        "ty = cuda.threadIdx.y\r\n",
        "bx = cuda.blockIdx.x\r\n",
        "by = cuda.blockIdx.y\r\n",
        "bw = cuda.blockDim.x\r\n",
        "bh = cuda.blockDim.y\r\n",
        "x = tx + bx * bw\r\n",
        "y = ty + by * bh\r\n",
        "array[x, y] = something(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HrBSoLW8BpS"
      },
      "source": [
        "Una implementación en código de lo anterior sería: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_FWIyeg8F2S"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    # Thread id in a 1D block\r\n",
        "    tx = cuda.threadIdx.x\r\n",
        "    # Block id in a 1D grid\r\n",
        "    ty = cuda.blockIdx.x\r\n",
        "    # Block width, i.e. number of threads per block\r\n",
        "    bw = cuda.blockDim.x\r\n",
        "    # Compute flattened index inside the array\r\n",
        "    pos = tx + ty * bw\r\n",
        "    if pos < an_array.size:  # Check array boundaries\r\n",
        "        an_array[pos] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvXx9Z5u8P_E"
      },
      "source": [
        "\r\n",
        "threadIdx, blockIdx, blockDim and gridDim son objetos especiales proporcionados por el backend CUDA con el único propósito de conocer la geometría de la jerarquía de subprocesos y la posición del subproceso actual dentro de esa geometría.\r\n",
        "\r\n",
        "Estos objetos pueden ser 1D, 2D o 3D, dependiendo de cómo se invocó el kernel. Para acceder al valor en cada dimensión, use los atributos x, y y z de estos objetos, respectivamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7xlhFvM8cfy"
      },
      "source": [
        "###**numba.cuda.threadIdx**\r\n",
        "\r\n",
        "Los índices de hilo en el bloque de hilo actual. Para bloques 1D, el índice (dado por el atributo x) es un número entero que abarca el rango de 0 inclusive a **numba.cuda.blockDim** exclusivo. Existe una regla similar para cada dimensión cuando se utiliza más de una dimensión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejIu_ve39U6Z"
      },
      "source": [
        "###**numba.cuda.blockDim**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "La forma del bloque de subprocesos, como se declaró al crear una instancia del kernel. Este valor es el mismo para todos los subprocesos en un kernel dado, incluso si pertenecen a bloques diferentes (es decir, cada bloque está \"lleno\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhBwHkze9krp"
      },
      "source": [
        "###**numba.cuda.blockIdx**\r\n",
        "\r\n",
        "Los índices de bloque en la cuadrícula de subprocesos lanzaron un kernel. Para una cuadrícula 1D, el índice (dado por el atributo x) es un número entero que abarca el rango de 0 inclusive a **numba.cuda.gridDim** exclusivo. Existe una regla similar para cada dimensión cuando se utiliza más de una dimensión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_TNrl5F9xXq"
      },
      "source": [
        "###**numba.cuda.gridDim**\r\n",
        "\r\n",
        "La forma de la grid de bloques, es decir, el número total de bloques lanzados por esta invocación del kernel, como se declaró al crear una instancia del kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTK26zP6_M2w"
      },
      "source": [
        "##Posición del Hilo (Subproceso) de manera compacta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPQwfyZs-EUU"
      },
      "source": [
        "###**numba.cuda.grid(ndim)**\r\n",
        "\r\n",
        "Devuelve la posición absoluta del hilo actual en toda la cuadrícula de **blocks. ndim** debe corresponder al número de dimensiones declaradas al crear una instancia del kernel. Si **ndim** es 1, se devuelve un solo entero. Si **ndim** es 2 o 3, se devuelve una tupla del número dado de enteros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPGyn81-qqY"
      },
      "source": [
        "\r\n",
        "###**numba.cuda.gridsize(ndim)**\r\n",
        "Devuelve el tamaño absoluto (o forma) en hilos de toda la cuadrícula de **blocks. ndim** tiene el mismo significado que en **grid ()** anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMjSPuz7_7Ev"
      },
      "source": [
        "Recordando que para un 1D-grid se tenia el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl8y5BxW_-7e"
      },
      "source": [
        "tx = cuda.threadIdx.x\r\n",
        "bx = cuda.blockIdx.x\r\n",
        "bw = cuda.blockDim.x\r\n",
        "i = tx + bx * bw\r\n",
        "array[i] = something(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M74xPSzN__u_"
      },
      "source": [
        "Con la notación compacta de **cuda.grid** queda de la siguiente manera.\r\n",
        "\r\n",
        "Para un 1D-grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8VbR0YGAKGu"
      },
      "source": [
        "i = cuda.grid(1)\r\n",
        "array[i] = something(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_XfXfBtAW9S"
      },
      "source": [
        "Recordando que para un 2D-grid se tenia el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbGAHJEQAbWx"
      },
      "source": [
        "tx = cuda.threadIdx.x\r\n",
        "ty = cuda.threadIdx.y\r\n",
        "bx = cuda.blockIdx.x\r\n",
        "by = cuda.blockIdx.y\r\n",
        "bw = cuda.blockDim.x\r\n",
        "bh = cuda.blockDim.y\r\n",
        "x = tx + bx * bw\r\n",
        "y = ty + by * bh\r\n",
        "array[x, y] = something(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSe4ghJlALC2"
      },
      "source": [
        "Con la notación compacta de **cuda.grid** queda de la siguiente manera.\r\n",
        "\r\n",
        "Para un 2D-grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvZmUJdAOJt"
      },
      "source": [
        "x, y = cuda.grid(2)\r\n",
        "array[x, y] = something(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPdowzRAAlTS"
      },
      "source": [
        "Una implementación para:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WflSehnAq6o"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    # Thread id in a 1D block\r\n",
        "    tx = cuda.threadIdx.x\r\n",
        "    # Block id in a 1D grid\r\n",
        "    ty = cuda.blockIdx.x\r\n",
        "    # Block width, i.e. number of threads per block\r\n",
        "    bw = cuda.blockDim.x\r\n",
        "    # Compute flattened index inside the array\r\n",
        "    pos = tx + ty * bw\r\n",
        "    if pos < an_array.size:  # Check array boundaries\r\n",
        "        an_array[pos] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-aUW23pAs7i"
      },
      "source": [
        "Con la notación compacta de **cuda.grid** queda de la siguiente manera.\r\n",
        "\r\n",
        "Para un 1D-grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSvWiV21AxYD"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    pos = cuda.grid(1)\r\n",
        "    if pos < an_array.size:\r\n",
        "        an_array[pos] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HARp1HgA4fb"
      },
      "source": [
        "Para un 2D-grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy4mcS1PA-oH"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_a_2D_array(an_array):\r\n",
        "    x, y = cuda.grid(2)\r\n",
        "    if x < an_array.shape[0] and y < an_array.shape[1]:\r\n",
        "       an_array[x, y] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IECWsmFcBK6a"
      },
      "source": [
        "La inicialización de este kernel podría ser la siguiente: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrXEBgehBSCC"
      },
      "source": [
        "threadsperblock = (16, 16)\r\n",
        "#  math.ceil take the integer closets \r\n",
        "blockspergrid_x = math.ceil(an_array.shape[0] / threadsperblock[0])\r\n",
        "blockspergrid_y = math.ceil(an_array.shape[1] / threadsperblock[1])\r\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\r\n",
        "increment_a_2D_array[blockspergrid, threadsperblock](an_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftcUuSuxwrvT"
      },
      "source": [
        "##Ejemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLVquykwvmO"
      },
      "source": [
        "###Código 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z00kS1jPwx1V",
        "outputId": "9005f838-8119-43a3-a545-0c227176f247"
      },
      "source": [
        "from numba import cuda\r\n",
        "import numpy as np\r\n",
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    # Thread id in a 1D block\r\n",
        "    tx = cuda.threadIdx.x\r\n",
        "    # Block id in a 1D grid\r\n",
        "    ty = cuda.blockIdx.x\r\n",
        "    # Block width, i.e. number of threads per block\r\n",
        "    bw = cuda.blockDim.x\r\n",
        "    # Compute flattened index inside the array\r\n",
        "    pos = tx + ty * bw\r\n",
        "    if pos < an_array.size:  # Check array boundaries\r\n",
        "        an_array[pos] += 1\r\n",
        "\r\n",
        "n = 32\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "threads_per_block=32\r\n",
        "blocks_per_grid=1\r\n",
        "print(\"Antes de lanzar el Kernel\")\r\n",
        "print(x)\r\n",
        "increment_by_one[threads_per_block,blocks_per_grid](x)\r\n",
        "print(\"Despues de lanzar el Kernel\")\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de lanzar el Kernel\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31.]\n",
            "Despues de lanzar el Kernel\n",
            "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
            " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGOEFsAnykRN"
      },
      "source": [
        "###Código 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmsyPNP4ymbR",
        "outputId": "334567ab-22e1-4743-9b55-a489a77203ca"
      },
      "source": [
        "from numba import cuda\r\n",
        "import numpy as np\r\n",
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "  pos=cuda.grid(1)\r\n",
        "  if pos < an_array.size:  # Check array boundaries\r\n",
        "    an_array[pos] += 1\r\n",
        "\r\n",
        "n = 32\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "threads_per_block=32\r\n",
        "blocks_per_grid=1\r\n",
        "print(\"Antes de lanzar el Kernel\")\r\n",
        "print(x)\r\n",
        "increment_by_one[threads_per_block,blocks_per_grid](x)\r\n",
        "print(\"Despues de lanzar el Kernel\")\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de lanzar el Kernel\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31.]\n",
            "Despues de lanzar el Kernel\n",
            "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
            " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xncD626fzyA5"
      },
      "source": [
        "###Código 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItWrHwXRzzzm",
        "outputId": "f097c813-7b2c-495b-85e9-ca7857e67f5f"
      },
      "source": [
        "from __future__ import division\r\n",
        "from numba import cuda\r\n",
        "import numpy\r\n",
        "import math\r\n",
        "\r\n",
        "# CUDA kernel\r\n",
        "@cuda.jit('void(float32[:])')\r\n",
        "def my_kernel(io_array):\r\n",
        "    pos = cuda.grid(1)\r\n",
        "    if pos < io_array.size:\r\n",
        "        io_array[pos] *= 2 # do the computation\r\n",
        "\r\n",
        "# Host code   \r\n",
        "data = numpy.ones(256).astype(np.float32)\r\n",
        "threadsperblock = 256\r\n",
        "blockspergrid = math.ceil(data.shape[0] / threadsperblock)\r\n",
        "my_kernel[blockspergrid, threadsperblock](data)\r\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejiV7EXB4xAH"
      },
      "source": [
        "###Código 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jVyQ_qV2rdf",
        "outputId": "66765705-b20b-4a01-ee4a-5e3f5b3cd83e"
      },
      "source": [
        "from numba import cuda\r\n",
        "import numpy as np \r\n",
        "import math \r\n",
        "@cuda.jit\r\n",
        "def sum_arrays(x_in,y_in):\r\n",
        "  tId=cuda.threadIdx.x\r\n",
        "  bId=cuda.blockIdx.x\r\n",
        "  DimBloc=cuda.blockDim.x\r\n",
        "\r\n",
        "  pos=tId+bId*DimBloc\r\n",
        "\r\n",
        "  if pos<x_in.size:\r\n",
        "    x_in[pos]=x_in[pos]+y_in[pos]\r\n",
        "\r\n",
        "\r\n",
        "n = 32\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "y=np.arange(n).astype(np.float32)\r\n",
        "\r\n",
        "threads_per_block=32\r\n",
        "blocks_per_grid=math.ceil(x.size/threads_per_block)\r\n",
        "\r\n",
        "print(\"Antes de lanzar el Kernel\")\r\n",
        "print(x)\r\n",
        "\r\n",
        "sum_arrays[blocks_per_grid,threads_per_block](x,y)\r\n",
        "print(\"Despues de lanzar el Kernel\")\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de lanzar el Kernel\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31.]\n",
            "Despues de lanzar el Kernel\n",
            "[ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18. 20. 22. 24. 26. 28. 30. 32. 34.\n",
            " 36. 38. 40. 42. 44. 46. 48. 50. 52. 54. 56. 58. 60. 62.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUxxiJSs4zT-"
      },
      "source": [
        "###Código 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWjyml2n40iu",
        "outputId": "f877127c-cba0-4174-891c-9651ad48c21b"
      },
      "source": [
        "@cuda.jit\r\n",
        "def add_kernel(x, y, out):\r\n",
        "    tidx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\r\n",
        "    bidx = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\r\n",
        "\r\n",
        "    block_dimx = cuda.blockDim.x  # number of threads per block\r\n",
        "    grid_dimx = cuda.gridDim.x    # number of blocks in the grid\r\n",
        "    \r\n",
        "    start = tidx + bidx * block_dimx\r\n",
        "    stride = block_dimx * grid_dimx\r\n",
        "\r\n",
        "    # assuming x and y inputs are same length\r\n",
        "    for i in range(start, x.shape[0], stride):\r\n",
        "        out[i] = x[i] + y[i]\r\n",
        "\r\n",
        "n = 100000\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "y = 2 * x\r\n",
        "out = np.empty_like(x)\r\n",
        "\r\n",
        "threads_per_block = 128\r\n",
        "blocks_per_grid = 30\r\n",
        "\r\n",
        "%timeit add_kernel[blocks_per_grid, threads_per_block](x, y, out)\r\n",
        "print(out[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 85.38 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 3: 2.01 ms per loop\n",
            "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk03c9ir4-p0",
        "outputId": "7cbafc45-f05b-4854-fc27-d0b269b0a2a8"
      },
      "source": [
        "@cuda.jit\r\n",
        "def add_kernel(x, y, out):\r\n",
        "    tidx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\r\n",
        "    bidx = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\r\n",
        "\r\n",
        "    block_dimx = cuda.blockDim.x  # number of threads per block\r\n",
        "    grid_dimx = cuda.gridDim.x    # number of blocks in the grid\r\n",
        "    \r\n",
        "    start = tidx + bidx * block_dimx\r\n",
        "    stride = block_dimx * grid_dimx\r\n",
        "\r\n",
        "    # assuming x and y inputs are same length\r\n",
        "    if start<x.size:\r\n",
        "        out[start] = x[start] + y[start]\r\n",
        "\r\n",
        "n = 100000\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "y = 2 * x\r\n",
        "out = np.empty_like(x)\r\n",
        "\r\n",
        "threads_per_block = 128\r\n",
        "blocks_per_grid = 30\r\n",
        "\r\n",
        "%timeit add_kernel[blocks_per_grid, threads_per_block](x, y, out)\r\n",
        "print(out[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 62.54 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 3: 2.04 ms per loop\n",
            "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSTeATMg5vx1",
        "outputId": "d28a0118-59f9-46fe-9dba-1a5f8cbeabf0"
      },
      "source": [
        "@cuda.jit\r\n",
        "def add_kernel(x, y, out):\r\n",
        "    start = cuda.grid(1)\r\n",
        "\r\n",
        "    # assuming x and y inputs are same length\r\n",
        "    if start<x.size:\r\n",
        "        out[start] = x[start] + y[start]\r\n",
        "\r\n",
        "n = 100000\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "y = 2 * x\r\n",
        "out = np.empty_like(x)\r\n",
        "\r\n",
        "threads_per_block = 128\r\n",
        "blocks_per_grid = 30\r\n",
        "\r\n",
        "%timeit add_kernel[blocks_per_grid, threads_per_block](x, y, out)\r\n",
        "print(out[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 61.80 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 3: 2.02 ms per loop\n",
            "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owEBlQg97T1V"
      },
      "source": [
        "##Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cmelKtXHoUn"
      },
      "source": [
        "###Código 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9BcAcJV7MgF",
        "outputId": "16fae945-1204-4c51-cdbf-a0967ef51b7a"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_a_2D_array(an_array):\r\n",
        "    x, y = cuda.grid(2)\r\n",
        "    if x < an_array.shape[0] and y < an_array.shape[1]:\r\n",
        "       an_array[x, y] += 1\r\n",
        "\r\n",
        "n = 1024\r\n",
        "x = np.arange(n).astype(np.float32).reshape((32,32))\r\n",
        "\r\n",
        "threads_per_block = 16\r\n",
        "blockdim=threads_per_block , threads_per_block\r\n",
        "\r\n",
        "griddim=math.ceil(n/ blockdim[0]), math.ceil(n/ blockdim[1])\r\n",
        "\r\n",
        "increment_a_2D_array[griddim, blockdim](x)\r\n",
        "print(x[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
            "   15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n",
            "   29.  30.  31.  32.]\n",
            " [ 33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.  45.  46.\n",
            "   47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.  60.\n",
            "   61.  62.  63.  64.]\n",
            " [ 65.  66.  67.  68.  69.  70.  71.  72.  73.  74.  75.  76.  77.  78.\n",
            "   79.  80.  81.  82.  83.  84.  85.  86.  87.  88.  89.  90.  91.  92.\n",
            "   93.  94.  95.  96.]\n",
            " [ 97.  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110.\n",
            "  111. 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124.\n",
            "  125. 126. 127. 128.]\n",
            " [129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140. 141. 142.\n",
            "  143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153. 154. 155. 156.\n",
            "  157. 158. 159. 160.]\n",
            " [161. 162. 163. 164. 165. 166. 167. 168. 169. 170. 171. 172. 173. 174.\n",
            "  175. 176. 177. 178. 179. 180. 181. 182. 183. 184. 185. 186. 187. 188.\n",
            "  189. 190. 191. 192.]\n",
            " [193. 194. 195. 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206.\n",
            "  207. 208. 209. 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220.\n",
            "  221. 222. 223. 224.]\n",
            " [225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237. 238.\n",
            "  239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251. 252.\n",
            "  253. 254. 255. 256.]\n",
            " [257. 258. 259. 260. 261. 262. 263. 264. 265. 266. 267. 268. 269. 270.\n",
            "  271. 272. 273. 274. 275. 276. 277. 278. 279. 280. 281. 282. 283. 284.\n",
            "  285. 286. 287. 288.]\n",
            " [289. 290. 291. 292. 293. 294. 295. 296. 297. 298. 299. 300. 301. 302.\n",
            "  303. 304. 305. 306. 307. 308. 309. 310. 311. 312. 313. 314. 315. 316.\n",
            "  317. 318. 319. 320.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHHmnQ0HsBV"
      },
      "source": [
        "###Código 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_EYoltl-JfP",
        "outputId": "7ba0873d-bdcd-4ab5-ff9b-eb906b2cd440"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_a_2D_array(an_array,an_array1):\r\n",
        "    x, y = cuda.grid(2)\r\n",
        "    if x < an_array.shape[0] and y < an_array.shape[1]:\r\n",
        "       an_array[x, y] = an_array[x, y] + an_array1[x, y]\r\n",
        "\r\n",
        "n = 1024\r\n",
        "x = np.arange(n).astype(np.float32).reshape((32,32))\r\n",
        "y=np.arange(n).astype(np.float32).reshape((32,32))\r\n",
        "threads_per_block = 16\r\n",
        "blockdim=threads_per_block , threads_per_block\r\n",
        "\r\n",
        "griddim=math.ceil(n/ blockdim[0]), math.ceil(n/ blockdim[1])\r\n",
        "print(griddim)\r\n",
        "increment_a_2D_array[griddim, blockdim](x,y)\r\n",
        "print(x[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 64)\n",
            "[[  0.   2.   4.   6.   8.  10.  12.  14.  16.  18.  20.  22.  24.  26.\n",
            "   28.  30.  32.  34.  36.  38.  40.  42.  44.  46.  48.  50.  52.  54.\n",
            "   56.  58.  60.  62.]\n",
            " [ 64.  66.  68.  70.  72.  74.  76.  78.  80.  82.  84.  86.  88.  90.\n",
            "   92.  94.  96.  98. 100. 102. 104. 106. 108. 110. 112. 114. 116. 118.\n",
            "  120. 122. 124. 126.]\n",
            " [128. 130. 132. 134. 136. 138. 140. 142. 144. 146. 148. 150. 152. 154.\n",
            "  156. 158. 160. 162. 164. 166. 168. 170. 172. 174. 176. 178. 180. 182.\n",
            "  184. 186. 188. 190.]\n",
            " [192. 194. 196. 198. 200. 202. 204. 206. 208. 210. 212. 214. 216. 218.\n",
            "  220. 222. 224. 226. 228. 230. 232. 234. 236. 238. 240. 242. 244. 246.\n",
            "  248. 250. 252. 254.]\n",
            " [256. 258. 260. 262. 264. 266. 268. 270. 272. 274. 276. 278. 280. 282.\n",
            "  284. 286. 288. 290. 292. 294. 296. 298. 300. 302. 304. 306. 308. 310.\n",
            "  312. 314. 316. 318.]\n",
            " [320. 322. 324. 326. 328. 330. 332. 334. 336. 338. 340. 342. 344. 346.\n",
            "  348. 350. 352. 354. 356. 358. 360. 362. 364. 366. 368. 370. 372. 374.\n",
            "  376. 378. 380. 382.]\n",
            " [384. 386. 388. 390. 392. 394. 396. 398. 400. 402. 404. 406. 408. 410.\n",
            "  412. 414. 416. 418. 420. 422. 424. 426. 428. 430. 432. 434. 436. 438.\n",
            "  440. 442. 444. 446.]\n",
            " [448. 450. 452. 454. 456. 458. 460. 462. 464. 466. 468. 470. 472. 474.\n",
            "  476. 478. 480. 482. 484. 486. 488. 490. 492. 494. 496. 498. 500. 502.\n",
            "  504. 506. 508. 510.]\n",
            " [512. 514. 516. 518. 520. 522. 524. 526. 528. 530. 532. 534. 536. 538.\n",
            "  540. 542. 544. 546. 548. 550. 552. 554. 556. 558. 560. 562. 564. 566.\n",
            "  568. 570. 572. 574.]\n",
            " [576. 578. 580. 582. 584. 586. 588. 590. 592. 594. 596. 598. 600. 602.\n",
            "  604. 606. 608. 610. 612. 614. 616. 618. 620. 622. 624. 626. 628. 630.\n",
            "  632. 634. 636. 638.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}