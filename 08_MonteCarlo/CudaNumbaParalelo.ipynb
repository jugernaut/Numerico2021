{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CudaNumbaParalelo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/Numerico2021/blob/desarrollo/08_MonteCarlo/CudaNumbaParalelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfK9rERkrYO0"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>Programación en Paralelo</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M.en.C. Miguel Angel Pérez León.</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón.</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Análisis Numérico.</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXfJOpOItu22"
      },
      "source": [
        "# Introducción\r\n",
        "\r\n",
        "Todos los algoritmos vistos en el curso se han descrito de manera [secuencial](https://desarrolloweb.com/articulos/2199.php), sin embargo muchos de ellos pueden ser redefinidos en su forma en **paralelo**.\r\n",
        "\r\n",
        "¿Por qué nos debería interesar programar en paralelo?, bueno la respuesta es muy sencilla, la gran mayoría (si no es que todas) de las aplicaciones que usamos actualmente son desarrolladas usando alguna técnica de programación en paralelo.\r\n",
        "\r\n",
        "¿Cuál es la principal ventaja de la programación en paralelo?, **la velocidad con la que este se ejecuta**, es decir el tiempo de ejecución. Un algoritmo en paralelo, debido a que distribuye los cálculos (FLOP's) entre los distintos dispositivos de cómputo tiende a reducir el tiempo de ejecución.\r\n",
        "\r\n",
        "CUDA (estandar de programación en paralelo basado en el lenguaje C) tiene un modelo de ejecución diferente al modelo secuencial tradicional utilizado para programar usando los CPU's disponibles. En CUDA, el código que escribes será ejecutado por varios subprocesos a la vez (a menudo cientos o miles dentro de la GPU), a diferencia de la programación secuencial en la cual cada [proceso](http://tecnologiasifa4b.blogspot.com/2015/08/proceso-computacional.html#:~:text=Un%20proceso%20computacional%20es%20u,de%20recursos%20del%20sistema%20asociados.&text=La%20ejecuci%C3%B3n%2C%20desde%20un%20proceso,la%20creaci%C3%B3n%20de%20otro%20proceso.) es ejecutado uno a la vez por cada CPU. Su solución se modelará definiendo una jerarquía de subprocesos de cuadrícula, bloques e subprocesos.\r\n",
        "\r\n",
        "El soporte CUDA de Numba Numba ([envoltorio](https://es.wikipedia.org/wiki/Wrapper) de CUDA para python) expone las instalaciones para declarar y administrar esta jerarquía de subprocesos. Las instalaciones y prestaciones son muy similares a las expuestas por el lenguaje C CUDA de NVidia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lxaDk7Y_8D-"
      },
      "source": [
        "## CPU v.s. GPU\n",
        "\n",
        "Actualmente los dispositivos de cómputo contienen al menos un CPU y dentro de este CPU pueden estar contenidos varios nucleos, lo que permite el desarrolo de algoritmos en paralelo.\n",
        "\n",
        "De igual, la mayoria de los dispositivos de cómputo contienen al menos un GPU y dentro de este GPU pueden existir varios nucleos, la principal diferencia entre ambos (CPU y GPU) es el proposito para el cuál fueron diseñados\n",
        "\n",
        "Para fines prácticos (y del curso) podemos pensar que la diferencia principal entre una CPU (unidad de procesamiento central) y una GPU (**unidad de procesamiento gráfico**) radíca en que un CPU es un dispositivo de cómputo de proposito general, puede realizar cualquier tipo de cómputo que se le asigne.\n",
        "\n",
        "Por otro lado un GPU esta diseñado para el procesamiento gráfico, lo que significa que la forma en la que procesa información **esta optimizada para trabajar con matrices y vectores**.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/desarrollo/Figuras/MonteCarlo/cpu-vs-gpu.jpg?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/desarrollo/Figuras/MonteCarlo/mejor.png?raw=1\" width=\"600\"> \n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GALRqhRpue9q"
      },
      "source": [
        "## ¿Qué es Numba?\r\n",
        "\r\n",
        "Según la documentación de Numba, \"Numba es un compilador justo a tiempo para Python que funciona mejor en código que usa matrices y funciones de NumPy, y ciclos.\r\n",
        "\r\n",
        "En otras palabras, Numba es una paqueteria (igual que Numpy o Matplotlib) que nos ayuda a que nuestros algoritmos se ejecuten de forma optimizada y en particular nos permite tener acceso a los GPU's disponibles en el hardware que estemos ejecutando nuestros algoritmos.\r\n",
        "\r\n",
        "La forma más común de usar Numba es a través de su colección de *decoradores* que se pueden aplicar a sus funciones para indicarle a Numba que las compile. Cuando se realiza una llamada a una función decorada de Numba, **se compila en código máquina** \"justo a tiempo\" para su ejecución y todo o parte de su código puede ejecutarse posteriormente a la ¡velocidad del código máquina nativo!.\r\n",
        "\r\n",
        "Para nuestros propósitos de hoy, Numba es un paquete de Python que le permite escribir código Python para GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkBX0-CvN2y"
      },
      "source": [
        "# Accediendo a la GPU de google colab\r\n",
        "\r\n",
        "1.   Para ejecutar las funciones de Numba usando las GPU's gratuitas de Google, tenemos que hacer un par de cosas. Primero, ir al menú *Runtime o Entorno de ejecución*, seleccionar *Cambiar tipo de tiempo de ejecución*, y en el cuadro emergente, en *Acelerador de hardware*, seleccione *GPU*, guardamos el cambio y listo.\r\n",
        "2.   Idealmente, eso es todo lo que deberíamos tener que hacer. Pero en la práctica, aunque las bibliotecas CUDA están instaladas, en el momento de escribir este jupyter, Colab no puede encontrarlas automáticamente. Entonces, hay que averiguar dónde están y luego indicarle a Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT2EQdkytuLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4f7b0a-2b5d-4232-9e4a-62c328291b83"
      },
      "source": [
        "!find / -iname 'libdevice'\r\n",
        "!find / -iname 'libnvvm.so'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.0/nvvm/libdevice\n",
            "/usr/local/cuda-10.1/nvvm/libdevice\n",
            "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n",
            "/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGyfEtgUvf4k"
      },
      "source": [
        "Se debe seleccionar y pegar la ubicación de las bibliotecas en el siguiente cuadro de código (de preferencia elegir las versiones más recientes):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYqtsk-Qj2rT"
      },
      "source": [
        "import os\r\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.1/nvvm/libdevice\"\r\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a1UNDfhvt1D"
      },
      "source": [
        "Una vez que ya se le indicó a colab donde encontrar las bibliotecas necesarias, podemos pasar por completo a python e importar la biblioteca de numba para cuda mediante las siguientes instrucciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEq5llWOj68-",
        "outputId": "a559dd09-5747-4f72-d7ef-1b704e950459"
      },
      "source": [
        "from numba import cuda\r\n",
        "import numba\r\n",
        "print(cuda.gpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Managed Device 0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9oKFWaNv24D"
      },
      "source": [
        "*print(cuda.gpus)* nos dice cuantos dispositivos GPU's tenemos disponibles y después de ejecutar la celda anterior deberiamos leer el mensaje \"<Managed Device 0>\" y esto indica que tenemos disponible una GPU, cuyo identificador es el 0 (cero)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7J7oOHfwBeM"
      },
      "source": [
        "# Sintaxis Numba\r\n",
        "\r\n",
        "Al hacer uso de Numba (CUDA), debemos tomar en cuenta que la finalidad de Numba es acelerar el desempeño de nuestros algoritmos.\r\n",
        "\r\n",
        "Para llevar a cabo tal proposito, Numba provee de sentencias que se agregan al código de python conocidos como *decoradores*. Estos decoradores son de diferentes tipos, ya que Numba permite acelerar el desempeño de diferentes formas\r\n",
        "\r\n",
        "algoritmos y esto se lleva a cabo distribuyendo los cálculos de nuestros algoritmos entre el CPU y el GPU, es por eso que Numba nos ofrece una forma para distiguir cuales de nuestras funciones se ejecutan en uno u otro dispositivo de cómputo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlujxYcPPsor"
      },
      "source": [
        "### ¡Justo a tiempo!\n",
        "\n",
        "El decorador más sencillo de usar en Numba es el decorador *@jit* y permite recibir multiples parametros, pero uno de los más elementales pero al mismo tiempo uno de los más usados, es el parametro* nopython=True*.\n",
        "\n",
        "Al hacer uso de este decorador se le indica a Numba que el código que pertenece a esta definición debe ser optimizado y esto se lleva a cabo, convirtiendo el código de python en **código de máquina**, esto toma un poco más de tiempo la primera vez que se ejecuta, pero las siguientes veces tomará mucho menos tiempo que una función en python nativo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeCZ8FZf8K1I"
      },
      "source": [
        "### Kernels\n",
        "\n",
        "Una función del tipo **Kernel** es una función de GPU que debe llamarse desde el código de la CPU$^{1}$ . Esta tiene dos características fundamentales:\n",
        "\n",
        "1.   Las funciones de tipo **Kernel** no pueden devolver explícitamente un valor; todos los datos de resultado deben escribirse en una matriz que se pasa a la función (si calcula un escalar, probablemente pasará una matriz de un elemento).\n",
        "2.   En una función de tipo **Kernel** se declara explícitamente su jerarquía de subprocesos cuando se les llama: es decir, el número de bloques de subprocesos y el número de subprocesos por bloque (hay que tener en cuenta que, si bien un kernel se compila una vez, se puede llamar varias veces con diferentes tamaños de bloque o tamaños de grid).\n",
        "\n",
        "Nota (1): Los dispositivos CUDA más nuevos admiten el lanzamiento del kernel del lado del dispositivo; esta característica se llama paralelismo dinámico pero Numba no la admite actualmente).\n",
        "\n",
        "A primera vista, escribir un función tipo kernel CUDA con Numba se parece mucho a escribir una función JIT para la CPU:\n",
        "\n",
        "El decorador @cuda.jit, le indica al interprete de python que esta función debe **traducirse a código de máquina** y por lo tanto su ejecución sera mucho más rapida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEUqOJIlkM7z"
      },
      "source": [
        "@cuda.jit\r\n",
        "def incremento_en_uno(arreglo):\r\n",
        "    \"\"\"\r\n",
        "    incrementa en uno los valores de un arreglo.\r\n",
        "    \"\"\"\r\n",
        "    # el codigo de este kernel va a aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diMNYgPlyRpk"
      },
      "source": [
        "## Lanzamiento de kernels\r\n",
        "\r\n",
        "Cuando se ejecuta (o lanza) una función de tipo kernel, se tiene que indicar el número de [hilos](https://1984.lsi.us.es/wiki-ssoo/index.php/Hilos) (procesos ligeros) que se van a encargar de ejecutar este kernel en paralelo.\r\n",
        "\r\n",
        "Hay dos maneras usuales de lanzar un Kernel en numba. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygj-8o4w1dly"
      },
      "source": [
        "###Forma 1 de lanzar kernel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygDMwnRHytJj"
      },
      "source": [
        "# dimension del grid (matriz)\r\n",
        "griddim = 1, 2\r\n",
        "# tamano del bloque de ejecucion\r\n",
        "blockdim = 3, 4\r\n",
        "#llamada (lanzamiento) del kernel\r\n",
        "incremento_en_uno[griddim, blockdim](arreglo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7RVlNnMzY5m"
      },
      "source": [
        "Que sería similar a cuando lanzas un *kernel* en Cuda C.Cómo se puede apreciar a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6kIPyalzRE0"
      },
      "source": [
        "dim3 griddim(1, 2);\r\n",
        "dim3 blockdim(3, 4);\r\n",
        "increment_by_one<<<griddim, blockdim>>>(aryA);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvl1eyOWzriv"
      },
      "source": [
        "griddim es el número de bloques de subprocesos por grid. Puede ser:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Un entero.\r\n",
        "*   Una 1-tupla de enteros.\r\n",
        "*   Una 2-tupla de enteros.\r\n",
        "\r\n",
        "blockdim es el número de subprocesos por bloque. Puede ser:\r\n",
        "\r\n",
        "*   Un entero.\r\n",
        "*   Una 1-tupla de enteros.\r\n",
        "*   Una 2-tupla de enteros.\r\n",
        "*   Una 3-tupla de enteros.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0wk_R0f1j8Z"
      },
      "source": [
        "###Forma 2 de lanzar kernel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5KE6g-X1rFC"
      },
      "source": [
        "threadsperblock = 32\r\n",
        "blockspergrid = (an_array.size + (threadsperblock - 1)) // threadsperblock\r\n",
        "increment_by_one[blockspergrid, threadsperblock](an_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXcbpoM12b-"
      },
      "source": [
        "Note dos cosas:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Cree una instancia del kernel propiamente dicho, especificando un número de bloques (o \"bloques por cuadrícula\") y un número de subprocesos por bloque. El producto de los dos dará el número total de hilos lanzados. La instanciación del kernel se realiza tomando la función del kernel compilada (aquí increment_by_one) e indexándola con una tupla de enteros.\r\n",
        "*   Ejecutando el kernel, pasándole la matriz de entrada (y cualquier matriz de salida separada si es necesario). Por defecto, ejecutar un kernel es sincrónico: la función regresa cuando el kernel ha terminado de ejecutarse y los datos se vuelven a sincronizar.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAv0ahrI4GSU"
      },
      "source": [
        "###Forma 3 de lanzar Kernel.\r\n",
        "\r\n",
        "En ocasiones queremos ser específicos con los datos que enviamos a los Kernel, debido a eso, a los decoradores de Numba les podemos pasar el tipo de dato que se procesará. Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A-W6bWG4gIY"
      },
      "source": [
        "@cuda.jit('void(int32[:], int32[:])')\r\n",
        "def foo(aryA, aryB):\r\n",
        "    \" Process some data \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z2aGgcA4oIg"
      },
      "source": [
        "En la función anterior, le decimos al programa que ingresamos dos 1D-arreglos de tipo entero ( int32[:] , int32[:] ) y extraemos ninguna información ( void ).\r\n",
        "\r\n",
        "También podemos lanzar un kernel, extrayendo algún dato, como se visualiza a continuación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwH-Gtne5P3t"
      },
      "source": [
        "@cuda.jit('int32(int32, int32)', device=True)\r\n",
        "def bar(a, b):\r\n",
        "    \" here computes the sum \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfSEIO685V0n"
      },
      "source": [
        "En la función anterior, le decimos al programa que ingresamos dos datos de tipo entero ( int32 , int32 ) y extraemosotro dato de tipo entero ( int32 )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8WVrsgH5nvf"
      },
      "source": [
        "@cuda.jit('void(int32[:], int32[:], int32[:])')\r\n",
        "def use_bar(aryA, aryB, aryOut):\r\n",
        "    i = cuda.grid(1) # global position of the thread for a 1D grid.\r\n",
        "    aryOut[i] = bar(aryA[i], aryB[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g5DB0rO503r"
      },
      "source": [
        "##Tamaño del bloque.\r\n",
        "\r\n",
        "Puede parecer curioso tener una jerarquía de dos niveles al declarar el número de subprocesos que necesita un Kernel. El tamaño del bloque (es decir, el número de subprocesos por bloque) suele ser crucial:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   En el lado del software, el tamaño del bloque determina cuántos subprocesos comparten un área determinada de memoria compartida.\r\n",
        "*   En el lado del hardware, el tamaño del bloque debe ser lo suficientemente grande para la ocupación completa de las unidades de ejecución; Las recomendaciones se pueden encontrar en la Guía de programación CUDA C\r\n",
        "\r\n",
        "Para ayudar a lidiar con matrices multidimensionales, CUDA le permite especificar bloques y cuadrículas multidimensionales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gcrIb707Jmo"
      },
      "source": [
        "##Posición del Hilo (Subproceso).\r\n",
        "\r\n",
        "Cuando se ejecuta un kernel, el código de la función del kernel es ejecutado por cada hilo una vez. Por lo tanto, tiene que saber en qué hilo se encuentra, para saber de qué elemento (s) de la matriz es responsable (los algoritmos complejos pueden definir responsabilidades más complejas, pero el principio subyacente es el mismo).\r\n",
        "\r\n",
        "Una forma es que el hilo determine su posición en la grid y en el bloque y calcule manualmente la posición de la matriz correspondiente:\r\n",
        "\r\n",
        "Para un 1D grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRXXD4--70Q_"
      },
      "source": [
        "tx = cuda.threadIdx.x\r\n",
        "bx = cuda.blockIdx.x\r\n",
        "bw = cuda.blockDim.x\r\n",
        "i = tx + bx * bw\r\n",
        "array[i] = something(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrR9LgKH72zy"
      },
      "source": [
        "Para un 2d grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm9949TF76so"
      },
      "source": [
        "tx = cuda.threadIdx.x\r\n",
        "ty = cuda.threadIdx.y\r\n",
        "bx = cuda.blockIdx.x\r\n",
        "by = cuda.blockIdx.y\r\n",
        "bw = cuda.blockDim.x\r\n",
        "bh = cuda.blockDim.y\r\n",
        "x = tx + bx * bw\r\n",
        "y = ty + by * bh\r\n",
        "array[x, y] = something(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HrBSoLW8BpS"
      },
      "source": [
        "Una implementación en código de lo anterior sería: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_FWIyeg8F2S"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    # Thread id in a 1D block\r\n",
        "    tx = cuda.threadIdx.x\r\n",
        "    # Block id in a 1D grid\r\n",
        "    ty = cuda.blockIdx.x\r\n",
        "    # Block width, i.e. number of threads per block\r\n",
        "    bw = cuda.blockDim.x\r\n",
        "    # Compute flattened index inside the array\r\n",
        "    pos = tx + ty * bw\r\n",
        "    if pos < an_array.size:  # Check array boundaries\r\n",
        "        an_array[pos] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvXx9Z5u8P_E"
      },
      "source": [
        "\r\n",
        "threadIdx, blockIdx, blockDim and gridDim son objetos especiales proporcionados por el backend CUDA con el único propósito de conocer la geometría de la jerarquía de subprocesos y la posición del subproceso actual dentro de esa geometría.\r\n",
        "\r\n",
        "Estos objetos pueden ser 1D, 2D o 3D, dependiendo de cómo se invocó el kernel. Para acceder al valor en cada dimensión, use los atributos x, y y z de estos objetos, respectivamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7xlhFvM8cfy"
      },
      "source": [
        "###**numba.cuda.threadIdx**\r\n",
        "\r\n",
        "Los índices de hilo en el bloque de hilo actual. Para bloques 1D, el índice (dado por el atributo x) es un número entero que abarca el rango de 0 inclusive a **numba.cuda.blockDim** exclusivo. Existe una regla similar para cada dimensión cuando se utiliza más de una dimensión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejIu_ve39U6Z"
      },
      "source": [
        "###**numba.cuda.blockDim**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "La forma del bloque de subprocesos, como se declaró al crear una instancia del kernel. Este valor es el mismo para todos los subprocesos en un kernel dado, incluso si pertenecen a bloques diferentes (es decir, cada bloque está \"lleno\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhBwHkze9krp"
      },
      "source": [
        "###**numba.cuda.blockIdx**\r\n",
        "\r\n",
        "Los índices de bloque en la cuadrícula de subprocesos lanzaron un kernel. Para una cuadrícula 1D, el índice (dado por el atributo x) es un número entero que abarca el rango de 0 inclusive a **numba.cuda.gridDim** exclusivo. Existe una regla similar para cada dimensión cuando se utiliza más de una dimensión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_TNrl5F9xXq"
      },
      "source": [
        "###**numba.cuda.gridDim**\r\n",
        "\r\n",
        "La forma de la grid de bloques, es decir, el número total de bloques lanzados por esta invocación del kernel, como se declaró al crear una instancia del kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTK26zP6_M2w"
      },
      "source": [
        "##Posición del Hilo (Subproceso) de manera compacta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPQwfyZs-EUU"
      },
      "source": [
        "###**numba.cuda.grid(ndim)**\r\n",
        "\r\n",
        "Devuelve la posición absoluta del hilo actual en toda la cuadrícula de **blocks. ndim** debe corresponder al número de dimensiones declaradas al crear una instancia del kernel. Si **ndim** es 1, se devuelve un solo entero. Si **ndim** es 2 o 3, se devuelve una tupla del número dado de enteros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPGyn81-qqY"
      },
      "source": [
        "\r\n",
        "###**numba.cuda.gridsize(ndim)**\r\n",
        "Devuelve el tamaño absoluto (o forma) en hilos de toda la cuadrícula de **blocks. ndim** tiene el mismo significado que en **grid ()** anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMjSPuz7_7Ev"
      },
      "source": [
        "Recordando que para un 1D-grid se tenia el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl8y5BxW_-7e"
      },
      "source": [
        "tx = cuda.threadIdx.x\r\n",
        "bx = cuda.blockIdx.x\r\n",
        "bw = cuda.blockDim.x\r\n",
        "i = tx + bx * bw\r\n",
        "array[i] = something(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M74xPSzN__u_"
      },
      "source": [
        "Con la notación compacta de **cuda.grid** queda de la siguiente manera.\r\n",
        "\r\n",
        "Para un 1D-grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8VbR0YGAKGu"
      },
      "source": [
        "i = cuda.grid(1)\r\n",
        "array[i] = something(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_XfXfBtAW9S"
      },
      "source": [
        "Recordando que para un 2D-grid se tenia el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbGAHJEQAbWx"
      },
      "source": [
        "tx = cuda.threadIdx.x\r\n",
        "ty = cuda.threadIdx.y\r\n",
        "bx = cuda.blockIdx.x\r\n",
        "by = cuda.blockIdx.y\r\n",
        "bw = cuda.blockDim.x\r\n",
        "bh = cuda.blockDim.y\r\n",
        "x = tx + bx * bw\r\n",
        "y = ty + by * bh\r\n",
        "array[x, y] = something(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSe4ghJlALC2"
      },
      "source": [
        "Con la notación compacta de **cuda.grid** queda de la siguiente manera.\r\n",
        "\r\n",
        "Para un 2D-grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvZmUJdAOJt"
      },
      "source": [
        "x, y = cuda.grid(2)\r\n",
        "array[x, y] = something(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPdowzRAAlTS"
      },
      "source": [
        "Una implementación para:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WflSehnAq6o"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    # Thread id in a 1D block\r\n",
        "    tx = cuda.threadIdx.x\r\n",
        "    # Block id in a 1D grid\r\n",
        "    ty = cuda.blockIdx.x\r\n",
        "    # Block width, i.e. number of threads per block\r\n",
        "    bw = cuda.blockDim.x\r\n",
        "    # Compute flattened index inside the array\r\n",
        "    pos = tx + ty * bw\r\n",
        "    if pos < an_array.size:  # Check array boundaries\r\n",
        "        an_array[pos] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-aUW23pAs7i"
      },
      "source": [
        "Con la notación compacta de **cuda.grid** queda de la siguiente manera.\r\n",
        "\r\n",
        "Para un 1D-grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSvWiV21AxYD"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    pos = cuda.grid(1)\r\n",
        "    if pos < an_array.size:\r\n",
        "        an_array[pos] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HARp1HgA4fb"
      },
      "source": [
        "Para un 2D-grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy4mcS1PA-oH"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_a_2D_array(an_array):\r\n",
        "    x, y = cuda.grid(2)\r\n",
        "    if x < an_array.shape[0] and y < an_array.shape[1]:\r\n",
        "       an_array[x, y] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IECWsmFcBK6a"
      },
      "source": [
        "La inicialización de este kernel podría ser la siguiente: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrXEBgehBSCC"
      },
      "source": [
        "threadsperblock = (16, 16)\r\n",
        "#  math.ceil take the integer closets \r\n",
        "blockspergrid_x = math.ceil(an_array.shape[0] / threadsperblock[0])\r\n",
        "blockspergrid_y = math.ceil(an_array.shape[1] / threadsperblock[1])\r\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\r\n",
        "increment_a_2D_array[blockspergrid, threadsperblock](an_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftcUuSuxwrvT"
      },
      "source": [
        "##Ejemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLVquykwvmO"
      },
      "source": [
        "###Código 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z00kS1jPwx1V",
        "outputId": "9005f838-8119-43a3-a545-0c227176f247"
      },
      "source": [
        "from numba import cuda\r\n",
        "import numpy as np\r\n",
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "    # Thread id in a 1D block\r\n",
        "    tx = cuda.threadIdx.x\r\n",
        "    # Block id in a 1D grid\r\n",
        "    ty = cuda.blockIdx.x\r\n",
        "    # Block width, i.e. number of threads per block\r\n",
        "    bw = cuda.blockDim.x\r\n",
        "    # Compute flattened index inside the array\r\n",
        "    pos = tx + ty * bw\r\n",
        "    if pos < an_array.size:  # Check array boundaries\r\n",
        "        an_array[pos] += 1\r\n",
        "\r\n",
        "n = 32\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "threads_per_block=32\r\n",
        "blocks_per_grid=1\r\n",
        "print(\"Antes de lanzar el Kernel\")\r\n",
        "print(x)\r\n",
        "increment_by_one[threads_per_block,blocks_per_grid](x)\r\n",
        "print(\"Despues de lanzar el Kernel\")\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de lanzar el Kernel\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31.]\n",
            "Despues de lanzar el Kernel\n",
            "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
            " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGOEFsAnykRN"
      },
      "source": [
        "###Código 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmsyPNP4ymbR",
        "outputId": "334567ab-22e1-4743-9b55-a489a77203ca"
      },
      "source": [
        "from numba import cuda\r\n",
        "import numpy as np\r\n",
        "@cuda.jit\r\n",
        "def increment_by_one(an_array):\r\n",
        "  pos=cuda.grid(1)\r\n",
        "  if pos < an_array.size:  # Check array boundaries\r\n",
        "    an_array[pos] += 1\r\n",
        "\r\n",
        "n = 32\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "threads_per_block=32\r\n",
        "blocks_per_grid=1\r\n",
        "print(\"Antes de lanzar el Kernel\")\r\n",
        "print(x)\r\n",
        "increment_by_one[threads_per_block,blocks_per_grid](x)\r\n",
        "print(\"Despues de lanzar el Kernel\")\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de lanzar el Kernel\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31.]\n",
            "Despues de lanzar el Kernel\n",
            "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
            " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xncD626fzyA5"
      },
      "source": [
        "###Código 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItWrHwXRzzzm",
        "outputId": "f097c813-7b2c-495b-85e9-ca7857e67f5f"
      },
      "source": [
        "from __future__ import division\r\n",
        "from numba import cuda\r\n",
        "import numpy\r\n",
        "import math\r\n",
        "\r\n",
        "# CUDA kernel\r\n",
        "@cuda.jit('void(float32[:])')\r\n",
        "def my_kernel(io_array):\r\n",
        "    pos = cuda.grid(1)\r\n",
        "    if pos < io_array.size:\r\n",
        "        io_array[pos] *= 2 # do the computation\r\n",
        "\r\n",
        "# Host code   \r\n",
        "data = numpy.ones(256).astype(np.float32)\r\n",
        "threadsperblock = 256\r\n",
        "blockspergrid = math.ceil(data.shape[0] / threadsperblock)\r\n",
        "my_kernel[blockspergrid, threadsperblock](data)\r\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejiV7EXB4xAH"
      },
      "source": [
        "###Código 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jVyQ_qV2rdf",
        "outputId": "66765705-b20b-4a01-ee4a-5e3f5b3cd83e"
      },
      "source": [
        "from numba import cuda\r\n",
        "import numpy as np \r\n",
        "import math \r\n",
        "@cuda.jit\r\n",
        "def sum_arrays(x_in,y_in):\r\n",
        "  tId=cuda.threadIdx.x\r\n",
        "  bId=cuda.blockIdx.x\r\n",
        "  DimBloc=cuda.blockDim.x\r\n",
        "\r\n",
        "  pos=tId+bId*DimBloc\r\n",
        "\r\n",
        "  if pos<x_in.size:\r\n",
        "    x_in[pos]=x_in[pos]+y_in[pos]\r\n",
        "\r\n",
        "\r\n",
        "n = 32\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "y=np.arange(n).astype(np.float32)\r\n",
        "\r\n",
        "threads_per_block=32\r\n",
        "blocks_per_grid=math.ceil(x.size/threads_per_block)\r\n",
        "\r\n",
        "print(\"Antes de lanzar el Kernel\")\r\n",
        "print(x)\r\n",
        "\r\n",
        "sum_arrays[blocks_per_grid,threads_per_block](x,y)\r\n",
        "print(\"Despues de lanzar el Kernel\")\r\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de lanzar el Kernel\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31.]\n",
            "Despues de lanzar el Kernel\n",
            "[ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18. 20. 22. 24. 26. 28. 30. 32. 34.\n",
            " 36. 38. 40. 42. 44. 46. 48. 50. 52. 54. 56. 58. 60. 62.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUxxiJSs4zT-"
      },
      "source": [
        "###Código 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWjyml2n40iu",
        "outputId": "f877127c-cba0-4174-891c-9651ad48c21b"
      },
      "source": [
        "@cuda.jit\r\n",
        "def add_kernel(x, y, out):\r\n",
        "    tidx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\r\n",
        "    bidx = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\r\n",
        "\r\n",
        "    block_dimx = cuda.blockDim.x  # number of threads per block\r\n",
        "    grid_dimx = cuda.gridDim.x    # number of blocks in the grid\r\n",
        "    \r\n",
        "    start = tidx + bidx * block_dimx\r\n",
        "    stride = block_dimx * grid_dimx\r\n",
        "\r\n",
        "    # assuming x and y inputs are same length\r\n",
        "    for i in range(start, x.shape[0], stride):\r\n",
        "        out[i] = x[i] + y[i]\r\n",
        "\r\n",
        "n = 100000\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "y = 2 * x\r\n",
        "out = np.empty_like(x)\r\n",
        "\r\n",
        "threads_per_block = 128\r\n",
        "blocks_per_grid = 30\r\n",
        "\r\n",
        "%timeit add_kernel[blocks_per_grid, threads_per_block](x, y, out)\r\n",
        "print(out[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 85.38 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 3: 2.01 ms per loop\n",
            "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk03c9ir4-p0",
        "outputId": "7cbafc45-f05b-4854-fc27-d0b269b0a2a8"
      },
      "source": [
        "@cuda.jit\r\n",
        "def add_kernel(x, y, out):\r\n",
        "    tidx = cuda.threadIdx.x # this is the unique thread ID within a 1D block\r\n",
        "    bidx = cuda.blockIdx.x  # Similarly, this is the unique block ID within the 1D grid\r\n",
        "\r\n",
        "    block_dimx = cuda.blockDim.x  # number of threads per block\r\n",
        "    grid_dimx = cuda.gridDim.x    # number of blocks in the grid\r\n",
        "    \r\n",
        "    start = tidx + bidx * block_dimx\r\n",
        "    stride = block_dimx * grid_dimx\r\n",
        "\r\n",
        "    # assuming x and y inputs are same length\r\n",
        "    if start<x.size:\r\n",
        "        out[start] = x[start] + y[start]\r\n",
        "\r\n",
        "n = 100000\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "y = 2 * x\r\n",
        "out = np.empty_like(x)\r\n",
        "\r\n",
        "threads_per_block = 128\r\n",
        "blocks_per_grid = 30\r\n",
        "\r\n",
        "%timeit add_kernel[blocks_per_grid, threads_per_block](x, y, out)\r\n",
        "print(out[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 62.54 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 3: 2.04 ms per loop\n",
            "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSTeATMg5vx1",
        "outputId": "d28a0118-59f9-46fe-9dba-1a5f8cbeabf0"
      },
      "source": [
        "@cuda.jit\r\n",
        "def add_kernel(x, y, out):\r\n",
        "    start = cuda.grid(1)\r\n",
        "\r\n",
        "    # assuming x and y inputs are same length\r\n",
        "    if start<x.size:\r\n",
        "        out[start] = x[start] + y[start]\r\n",
        "\r\n",
        "n = 100000\r\n",
        "x = np.arange(n).astype(np.float32)\r\n",
        "y = 2 * x\r\n",
        "out = np.empty_like(x)\r\n",
        "\r\n",
        "threads_per_block = 128\r\n",
        "blocks_per_grid = 30\r\n",
        "\r\n",
        "%timeit add_kernel[blocks_per_grid, threads_per_block](x, y, out)\r\n",
        "print(out[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 61.80 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 3: 2.02 ms per loop\n",
            "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owEBlQg97T1V"
      },
      "source": [
        "##Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cmelKtXHoUn"
      },
      "source": [
        "###Código 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9BcAcJV7MgF",
        "outputId": "16fae945-1204-4c51-cdbf-a0967ef51b7a"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_a_2D_array(an_array):\r\n",
        "    x, y = cuda.grid(2)\r\n",
        "    if x < an_array.shape[0] and y < an_array.shape[1]:\r\n",
        "       an_array[x, y] += 1\r\n",
        "\r\n",
        "n = 1024\r\n",
        "x = np.arange(n).astype(np.float32).reshape((32,32))\r\n",
        "\r\n",
        "threads_per_block = 16\r\n",
        "blockdim=threads_per_block , threads_per_block\r\n",
        "\r\n",
        "griddim=math.ceil(n/ blockdim[0]), math.ceil(n/ blockdim[1])\r\n",
        "\r\n",
        "increment_a_2D_array[griddim, blockdim](x)\r\n",
        "print(x[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
            "   15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n",
            "   29.  30.  31.  32.]\n",
            " [ 33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.  45.  46.\n",
            "   47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.  60.\n",
            "   61.  62.  63.  64.]\n",
            " [ 65.  66.  67.  68.  69.  70.  71.  72.  73.  74.  75.  76.  77.  78.\n",
            "   79.  80.  81.  82.  83.  84.  85.  86.  87.  88.  89.  90.  91.  92.\n",
            "   93.  94.  95.  96.]\n",
            " [ 97.  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110.\n",
            "  111. 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124.\n",
            "  125. 126. 127. 128.]\n",
            " [129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140. 141. 142.\n",
            "  143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153. 154. 155. 156.\n",
            "  157. 158. 159. 160.]\n",
            " [161. 162. 163. 164. 165. 166. 167. 168. 169. 170. 171. 172. 173. 174.\n",
            "  175. 176. 177. 178. 179. 180. 181. 182. 183. 184. 185. 186. 187. 188.\n",
            "  189. 190. 191. 192.]\n",
            " [193. 194. 195. 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206.\n",
            "  207. 208. 209. 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220.\n",
            "  221. 222. 223. 224.]\n",
            " [225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237. 238.\n",
            "  239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251. 252.\n",
            "  253. 254. 255. 256.]\n",
            " [257. 258. 259. 260. 261. 262. 263. 264. 265. 266. 267. 268. 269. 270.\n",
            "  271. 272. 273. 274. 275. 276. 277. 278. 279. 280. 281. 282. 283. 284.\n",
            "  285. 286. 287. 288.]\n",
            " [289. 290. 291. 292. 293. 294. 295. 296. 297. 298. 299. 300. 301. 302.\n",
            "  303. 304. 305. 306. 307. 308. 309. 310. 311. 312. 313. 314. 315. 316.\n",
            "  317. 318. 319. 320.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHHmnQ0HsBV"
      },
      "source": [
        "###Código 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_EYoltl-JfP",
        "outputId": "7ba0873d-bdcd-4ab5-ff9b-eb906b2cd440"
      },
      "source": [
        "@cuda.jit\r\n",
        "def increment_a_2D_array(an_array,an_array1):\r\n",
        "    x, y = cuda.grid(2)\r\n",
        "    if x < an_array.shape[0] and y < an_array.shape[1]:\r\n",
        "       an_array[x, y] = an_array[x, y] + an_array1[x, y]\r\n",
        "\r\n",
        "n = 1024\r\n",
        "x = np.arange(n).astype(np.float32).reshape((32,32))\r\n",
        "y=np.arange(n).astype(np.float32).reshape((32,32))\r\n",
        "threads_per_block = 16\r\n",
        "blockdim=threads_per_block , threads_per_block\r\n",
        "\r\n",
        "griddim=math.ceil(n/ blockdim[0]), math.ceil(n/ blockdim[1])\r\n",
        "print(griddim)\r\n",
        "increment_a_2D_array[griddim, blockdim](x,y)\r\n",
        "print(x[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 64)\n",
            "[[  0.   2.   4.   6.   8.  10.  12.  14.  16.  18.  20.  22.  24.  26.\n",
            "   28.  30.  32.  34.  36.  38.  40.  42.  44.  46.  48.  50.  52.  54.\n",
            "   56.  58.  60.  62.]\n",
            " [ 64.  66.  68.  70.  72.  74.  76.  78.  80.  82.  84.  86.  88.  90.\n",
            "   92.  94.  96.  98. 100. 102. 104. 106. 108. 110. 112. 114. 116. 118.\n",
            "  120. 122. 124. 126.]\n",
            " [128. 130. 132. 134. 136. 138. 140. 142. 144. 146. 148. 150. 152. 154.\n",
            "  156. 158. 160. 162. 164. 166. 168. 170. 172. 174. 176. 178. 180. 182.\n",
            "  184. 186. 188. 190.]\n",
            " [192. 194. 196. 198. 200. 202. 204. 206. 208. 210. 212. 214. 216. 218.\n",
            "  220. 222. 224. 226. 228. 230. 232. 234. 236. 238. 240. 242. 244. 246.\n",
            "  248. 250. 252. 254.]\n",
            " [256. 258. 260. 262. 264. 266. 268. 270. 272. 274. 276. 278. 280. 282.\n",
            "  284. 286. 288. 290. 292. 294. 296. 298. 300. 302. 304. 306. 308. 310.\n",
            "  312. 314. 316. 318.]\n",
            " [320. 322. 324. 326. 328. 330. 332. 334. 336. 338. 340. 342. 344. 346.\n",
            "  348. 350. 352. 354. 356. 358. 360. 362. 364. 366. 368. 370. 372. 374.\n",
            "  376. 378. 380. 382.]\n",
            " [384. 386. 388. 390. 392. 394. 396. 398. 400. 402. 404. 406. 408. 410.\n",
            "  412. 414. 416. 418. 420. 422. 424. 426. 428. 430. 432. 434. 436. 438.\n",
            "  440. 442. 444. 446.]\n",
            " [448. 450. 452. 454. 456. 458. 460. 462. 464. 466. 468. 470. 472. 474.\n",
            "  476. 478. 480. 482. 484. 486. 488. 490. 492. 494. 496. 498. 500. 502.\n",
            "  504. 506. 508. 510.]\n",
            " [512. 514. 516. 518. 520. 522. 524. 526. 528. 530. 532. 534. 536. 538.\n",
            "  540. 542. 544. 546. 548. 550. 552. 554. 556. 558. 560. 562. 564. 566.\n",
            "  568. 570. 572. 574.]\n",
            " [576. 578. 580. 582. 584. 586. 588. 590. 592. 594. 596. 598. 600. 602.\n",
            "  604. 606. 608. 610. 612. 614. 616. 618. 620. 622. 624. 626. 628. 630.\n",
            "  632. 634. 636. 638.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}